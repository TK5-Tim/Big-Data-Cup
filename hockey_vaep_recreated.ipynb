{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Big Data Cup 2021 \n",
    "## How to value Zone Entries and other actions that are not shots or goals\n",
    "### VAEP (Valuing actions by estimating probabilities) framework for Hockey \n",
    "Inspired by paper of the Soccer version [Actions Speak Louder Than Goals: Valuing Player Actions in Soccer](https://arxiv.org/abs/1802.07127) by Tom Decroos, Lotte Bransen, Jan Van Haaren and Jesse Davis. Very helpful was the Tutorial as part of the Friends of Tracking initiative by Lotte Bransen and Jan Van Haaren: [Friends of Tracking: Valuing actions in football](https://github.com/SciSports-Labs/fot-valuing-actions)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"%reload_ext nb_black\\nimport pandas as pd\\nfrom tqdm import tqdm\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.metrics import brier_score_loss, roc_auc_score\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.calibration import CalibratedClassifierCV\\nfrom sklearn.model_selection import KFold\\nfrom xgboost import XGBClassifier, plot_importance\\n\\nimport shap\\nfrom ipywidgets import interact_manual, fixed, widgets\\n%matplotlib inline\";\n                var nbb_formatted_code = \"%reload_ext nb_black\\nimport pandas as pd\\nfrom tqdm import tqdm\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.metrics import brier_score_loss, roc_auc_score\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.calibration import CalibratedClassifierCV\\nfrom sklearn.model_selection import KFold\\nfrom xgboost import XGBClassifier, plot_importance\\n\\nimport shap\\nfrom ipywidgets import interact_manual, fixed, widgets\\n\\n%matplotlib inline\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "%reload_ext nb_black\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "import shap\n",
    "from ipywidgets import interact_manual, fixed, widgets\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "# Importing data, renaming columns, creating extra columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# Import and Data Frame for womens data\\nproject_dir = '/Users/keltim01/git_repos/TK5/Data/Big-Data-Cup-2021/'\\nwomens = pd.read_csv(project_dir + 'hackathon_womens.csv')\\nnwhl = pd.read_csv(project_dir + 'hackathon_nwhl.csv')\\nwomens = womens.append(nwhl, ignore_index=True)\\n# important numbers for the hockey rink \\nICE_LENGTH = 200\\nICE_WIDTH = 85\\nGOAL_X = ICE_LENGTH - 10\\nGOAL_Y = ICE_WIDTH / 2\\nD_ZONE = 75\\nO_ZONE = ICE_LENGTH - 75\\n\\nwomens.columns = ['game_date', 'home_team', 'away_team', 'period', 'clock', 'home_team_skaters', 'away_team_skaters', 'home_team_goals','away_team_goals', 'team', 'player', 'event', 'x_coord', 'y_coord', 'detail_1', 'detail_2', 'detail_3', 'detail_4', 'player_2', 'x_coord_2', 'y_coord_2']\\nwomens['game_id'] = womens.loc[:, ['game_date', 'home_team', 'away_team']].sum(axis=1).astype('category').cat.codes\\nwomens['is_home'] = 0\\nwomens['is_shot'] = 0\\nwomens['is_goal'] = 0\\nwomens['event_id'] = womens['event'].astype('category').cat.codes\\nwomens['team_id'] = womens['team'].astype('category').cat.codes\\nwomens['player_id'] = womens['player'].astype('category').cat.codes\\n\\nfor x in range(1,5):\\n    womens[f'detail_{x}_code'] = womens[f'detail_{x}'].astype('category').cat.codes\\nwomens.loc[womens['home_team'] == womens['team'], 'is_home'] = 1\\nwomens.loc[womens['event']=='Shot', 'is_shot'] = 1\\nwomens.loc[womens['event']=='Goal', 'is_goal'] = 1\\nwomens['goal_diff'] = womens['home_team_goals'].sub(womens['away_team_goals'])\\nwomens['clock'] = pd.to_datetime(womens['clock'], format='%M:%S')\\nwomens['seconds_remaining'] = womens['clock'].dt.minute.mul(60).add(womens['clock'].dt.second)\";\n                var nbb_formatted_code = \"# Import and Data Frame for womens data\\nproject_dir = \\\"/Users/keltim01/git_repos/TK5/Data/Big-Data-Cup-2021/\\\"\\nwomens = pd.read_csv(project_dir + \\\"hackathon_womens.csv\\\")\\nnwhl = pd.read_csv(project_dir + \\\"hackathon_nwhl.csv\\\")\\nwomens = womens.append(nwhl, ignore_index=True)\\n# important numbers for the hockey rink\\nICE_LENGTH = 200\\nICE_WIDTH = 85\\nGOAL_X = ICE_LENGTH - 10\\nGOAL_Y = ICE_WIDTH / 2\\nD_ZONE = 75\\nO_ZONE = ICE_LENGTH - 75\\n\\nwomens.columns = [\\n    \\\"game_date\\\",\\n    \\\"home_team\\\",\\n    \\\"away_team\\\",\\n    \\\"period\\\",\\n    \\\"clock\\\",\\n    \\\"home_team_skaters\\\",\\n    \\\"away_team_skaters\\\",\\n    \\\"home_team_goals\\\",\\n    \\\"away_team_goals\\\",\\n    \\\"team\\\",\\n    \\\"player\\\",\\n    \\\"event\\\",\\n    \\\"x_coord\\\",\\n    \\\"y_coord\\\",\\n    \\\"detail_1\\\",\\n    \\\"detail_2\\\",\\n    \\\"detail_3\\\",\\n    \\\"detail_4\\\",\\n    \\\"player_2\\\",\\n    \\\"x_coord_2\\\",\\n    \\\"y_coord_2\\\",\\n]\\nwomens[\\\"game_id\\\"] = (\\n    womens.loc[:, [\\\"game_date\\\", \\\"home_team\\\", \\\"away_team\\\"]]\\n    .sum(axis=1)\\n    .astype(\\\"category\\\")\\n    .cat.codes\\n)\\nwomens[\\\"is_home\\\"] = 0\\nwomens[\\\"is_shot\\\"] = 0\\nwomens[\\\"is_goal\\\"] = 0\\nwomens[\\\"event_id\\\"] = womens[\\\"event\\\"].astype(\\\"category\\\").cat.codes\\nwomens[\\\"team_id\\\"] = womens[\\\"team\\\"].astype(\\\"category\\\").cat.codes\\nwomens[\\\"player_id\\\"] = womens[\\\"player\\\"].astype(\\\"category\\\").cat.codes\\n\\nfor x in range(1, 5):\\n    womens[f\\\"detail_{x}_code\\\"] = womens[f\\\"detail_{x}\\\"].astype(\\\"category\\\").cat.codes\\nwomens.loc[womens[\\\"home_team\\\"] == womens[\\\"team\\\"], \\\"is_home\\\"] = 1\\nwomens.loc[womens[\\\"event\\\"] == \\\"Shot\\\", \\\"is_shot\\\"] = 1\\nwomens.loc[womens[\\\"event\\\"] == \\\"Goal\\\", \\\"is_goal\\\"] = 1\\nwomens[\\\"goal_diff\\\"] = womens[\\\"home_team_goals\\\"].sub(womens[\\\"away_team_goals\\\"])\\nwomens[\\\"clock\\\"] = pd.to_datetime(womens[\\\"clock\\\"], format=\\\"%M:%S\\\")\\nwomens[\\\"seconds_remaining\\\"] = (\\n    womens[\\\"clock\\\"].dt.minute.mul(60).add(womens[\\\"clock\\\"].dt.second)\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Import and Data Frame for womens data\n",
    "project_dir = '/Users/keltim01/git_repos/TK5/Data/Big-Data-Cup-2021/'\n",
    "womens = pd.read_csv(project_dir + 'hackathon_womens.csv')\n",
    "nwhl = pd.read_csv(project_dir + 'hackathon_nwhl.csv')\n",
    "womens = womens.append(nwhl, ignore_index=True)\n",
    "# important numbers for the hockey rink \n",
    "ICE_LENGTH = 200\n",
    "ICE_WIDTH = 85\n",
    "GOAL_X = ICE_LENGTH - 10\n",
    "GOAL_Y = ICE_WIDTH / 2\n",
    "D_ZONE = 75\n",
    "O_ZONE = ICE_LENGTH - 75\n",
    "\n",
    "womens.columns = ['game_date', 'home_team', 'away_team', 'period', 'clock', 'home_team_skaters', 'away_team_skaters', 'home_team_goals','away_team_goals', 'team', 'player', 'event', 'x_coord', 'y_coord', 'detail_1', 'detail_2', 'detail_3', 'detail_4', 'player_2', 'x_coord_2', 'y_coord_2']\n",
    "womens['game_id'] = womens.loc[:, ['game_date', 'home_team', 'away_team']].sum(axis=1).astype('category').cat.codes\n",
    "womens['is_home'] = 0\n",
    "womens['is_shot'] = 0\n",
    "womens['is_goal'] = 0\n",
    "womens['event_id'] = womens['event'].astype('category').cat.codes\n",
    "womens['team_id'] = womens['team'].astype('category').cat.codes\n",
    "womens['player_id'] = womens['player'].astype('category').cat.codes\n",
    "\n",
    "for x in range(1,5):\n",
    "    womens[f'detail_{x}_code'] = womens[f'detail_{x}'].astype('category').cat.codes\n",
    "womens.loc[womens['home_team'] == womens['team'], 'is_home'] = 1\n",
    "womens.loc[womens['event']=='Shot', 'is_shot'] = 1\n",
    "womens.loc[womens['event']=='Goal', 'is_goal'] = 1\n",
    "womens['goal_diff'] = womens['home_team_goals'].sub(womens['away_team_goals'])\n",
    "womens['clock'] = pd.to_datetime(womens['clock'], format='%M:%S')\n",
    "womens['seconds_remaining'] = womens['clock'].dt.minute.mul(60).add(womens['clock'].dt.second)"
   ]
  },
  {
   "source": [
    "## Possession gained/lost\n",
    "* Shot: which team has the puck recovery? (next event)\n",
    "* Goal: not interesting because you scored -> 0\n",
    "* Play: possession stays -> 0\n",
    "* Incomplete Play: Possession lost -> -1\n",
    "* Takeaway: Possession won \n",
    "* Puck recovery: according to the team Possessing the puck before \n",
    "* Dump In/out: team recovering the puck \n",
    "* Zone Entry: \n",
    "    * carried: possesion retained \n",
    "    * dump in: next event \n",
    "    * passed: possesion retained \n",
    "* Faceoff Win: Possession gained\n",
    "* Penalty Taken: Possession 0 like goal\n",
    "\n",
    "## Glossary \n",
    "* -1 possesion lost through action \n",
    "* 0 possesion stays the same \n",
    "* 1 possesion gained through action"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"womens.loc[(womens['event']=='Shot') & (womens['team']==womens['team'].shift(-1)),'poss_status'] = 0\\nwomens.loc[(womens['event']=='Shot') & (womens['team']!=womens['team'].shift(-1)),'poss_status'] = -1\\nwomens.loc[(womens['event']=='Puck Recovery') & (womens['team']!=womens['team'].shift(1)),'poss_status'] = 1\\nwomens.loc[(womens['event']=='Puck Recovery') & (womens['team']==womens['team'].shift(1)),'poss_status'] = 0\\nwomens.loc[(womens['event']=='Dump In/Out') & (womens['team']==womens['team'].shift(-1)),'poss_status'] = 0\\nwomens.loc[(womens['event']=='Dump In/Out') & (womens['team']!=womens['team'].shift(-1)),'poss_status'] = -1\\nwomens.loc[womens['event']=='Goal','poss_status'] = 0\\nwomens.loc[womens['event']=='Takeaway','poss_status'] = 1\\nwomens.loc[womens['event']=='Play','poss_status'] = 0\\nwomens.loc[womens['event']=='Incomplete Play','poss_status'] = -1\\nwomens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Carried'),'poss_status'] = 0\\nwomens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Passed'),'poss_status'] = 0\\nwomens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped') & (womens['event'].shift(-1) == 'Faceoff Win'),'poss_status'] = 0\\nwomens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped') & (womens['event'].shift(-1) == 'Penalty Taken'),'poss_status'] = 0\\nwomens.loc[(womens['team']==womens['team'].shift(-1)) & (womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped') & (womens['event'].shift(-1) == 'Puck Recovery'),'poss_status'] = 0\\nwomens.loc[(womens['team']!=womens['team'].shift(-1)) & (womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped') & (womens['event'].shift(-1) == 'Puck Recovery'),'poss_status'] = -1\\nwomens.loc[womens['event']=='Faceoff Win','poss_status'] = 1\\nwomens.loc[womens['event']=='Penalty Taken','poss_status'] = 0\";\n                var nbb_formatted_code = \"womens.loc[\\n    (womens[\\\"event\\\"] == \\\"Shot\\\") & (womens[\\\"team\\\"] == womens[\\\"team\\\"].shift(-1)),\\n    \\\"poss_status\\\",\\n] = 0\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Shot\\\") & (womens[\\\"team\\\"] != womens[\\\"team\\\"].shift(-1)),\\n    \\\"poss_status\\\",\\n] = -1\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Puck Recovery\\\") & (womens[\\\"team\\\"] != womens[\\\"team\\\"].shift(1)),\\n    \\\"poss_status\\\",\\n] = 1\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Puck Recovery\\\") & (womens[\\\"team\\\"] == womens[\\\"team\\\"].shift(1)),\\n    \\\"poss_status\\\",\\n] = 0\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Dump In/Out\\\") & (womens[\\\"team\\\"] == womens[\\\"team\\\"].shift(-1)),\\n    \\\"poss_status\\\",\\n] = 0\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Dump In/Out\\\") & (womens[\\\"team\\\"] != womens[\\\"team\\\"].shift(-1)),\\n    \\\"poss_status\\\",\\n] = -1\\nwomens.loc[womens[\\\"event\\\"] == \\\"Goal\\\", \\\"poss_status\\\"] = 0\\nwomens.loc[womens[\\\"event\\\"] == \\\"Takeaway\\\", \\\"poss_status\\\"] = 1\\nwomens.loc[womens[\\\"event\\\"] == \\\"Play\\\", \\\"poss_status\\\"] = 0\\nwomens.loc[womens[\\\"event\\\"] == \\\"Incomplete Play\\\", \\\"poss_status\\\"] = -1\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Zone Entry\\\") & (womens[\\\"detail_1\\\"] == \\\"Carried\\\"), \\\"poss_status\\\"\\n] = 0\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Zone Entry\\\") & (womens[\\\"detail_1\\\"] == \\\"Passed\\\"), \\\"poss_status\\\"\\n] = 0\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Zone Entry\\\")\\n    & (womens[\\\"detail_1\\\"] == \\\"Dumped\\\")\\n    & (womens[\\\"event\\\"].shift(-1) == \\\"Faceoff Win\\\"),\\n    \\\"poss_status\\\",\\n] = 0\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Zone Entry\\\")\\n    & (womens[\\\"detail_1\\\"] == \\\"Dumped\\\")\\n    & (womens[\\\"event\\\"].shift(-1) == \\\"Penalty Taken\\\"),\\n    \\\"poss_status\\\",\\n] = 0\\nwomens.loc[\\n    (womens[\\\"team\\\"] == womens[\\\"team\\\"].shift(-1))\\n    & (womens[\\\"event\\\"] == \\\"Zone Entry\\\")\\n    & (womens[\\\"detail_1\\\"] == \\\"Dumped\\\")\\n    & (womens[\\\"event\\\"].shift(-1) == \\\"Puck Recovery\\\"),\\n    \\\"poss_status\\\",\\n] = 0\\nwomens.loc[\\n    (womens[\\\"team\\\"] != womens[\\\"team\\\"].shift(-1))\\n    & (womens[\\\"event\\\"] == \\\"Zone Entry\\\")\\n    & (womens[\\\"detail_1\\\"] == \\\"Dumped\\\")\\n    & (womens[\\\"event\\\"].shift(-1) == \\\"Puck Recovery\\\"),\\n    \\\"poss_status\\\",\\n] = -1\\nwomens.loc[womens[\\\"event\\\"] == \\\"Faceoff Win\\\", \\\"poss_status\\\"] = 1\\nwomens.loc[womens[\\\"event\\\"] == \\\"Penalty Taken\\\", \\\"poss_status\\\"] = 0\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens.loc[(womens['event']=='Shot') & (womens['team']==womens['team'].shift(-1)),'poss_status'] = 0\n",
    "womens.loc[(womens['event']=='Shot') & (womens['team']!=womens['team'].shift(-1)),'poss_status'] = -1\n",
    "womens.loc[(womens['event']=='Puck Recovery') & (womens['team']!=womens['team'].shift(1)),'poss_status'] = 1\n",
    "womens.loc[(womens['event']=='Puck Recovery') & (womens['team']==womens['team'].shift(1)),'poss_status'] = 0\n",
    "womens.loc[(womens['event']=='Dump In/Out') & (womens['team']==womens['team'].shift(-1)),'poss_status'] = 0\n",
    "womens.loc[(womens['event']=='Dump In/Out') & (womens['team']!=womens['team'].shift(-1)),'poss_status'] = -1\n",
    "womens.loc[womens['event']=='Goal','poss_status'] = 0\n",
    "womens.loc[womens['event']=='Takeaway','poss_status'] = 1\n",
    "womens.loc[womens['event']=='Play','poss_status'] = 0\n",
    "womens.loc[womens['event']=='Incomplete Play','poss_status'] = -1\n",
    "womens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Carried'),'poss_status'] = 0\n",
    "womens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Passed'),'poss_status'] = 0\n",
    "womens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped') & (womens['event'].shift(-1) == 'Faceoff Win'),'poss_status'] = 0\n",
    "womens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped') & (womens['event'].shift(-1) == 'Penalty Taken'),'poss_status'] = 0\n",
    "womens.loc[(womens['team']==womens['team'].shift(-1)) & (womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped') & (womens['event'].shift(-1) == 'Puck Recovery'),'poss_status'] = 0\n",
    "womens.loc[(womens['team']!=womens['team'].shift(-1)) & (womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped') & (womens['event'].shift(-1) == 'Puck Recovery'),'poss_status'] = -1\n",
    "womens.loc[womens['event']=='Faceoff Win','poss_status'] = 1\n",
    "womens.loc[womens['event']=='Penalty Taken','poss_status'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "poss_status  event          \n",
       " 0.0         Play               14673\n",
       " 1.0         Puck Recovery       9368\n",
       "-1.0         Incomplete Play     6111\n",
       " 0.0         Puck Recovery       5806\n",
       "             Zone Entry          2555\n",
       "-1.0         Dump In/Out         2106\n",
       " 1.0         Takeaway            2092\n",
       " 0.0         Shot                1917\n",
       " 1.0         Faceoff Win         1629\n",
       "-1.0         Shot                1607\n",
       " 0.0         Dump In/Out         1439\n",
       "-1.0         Zone Entry           928\n",
       " 0.0         Penalty Taken        260\n",
       "             Goal                 132\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"womens[['poss_status','event']].value_counts()\";\n                var nbb_formatted_code = \"womens[[\\\"poss_status\\\", \\\"event\\\"]].value_counts()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens[['poss_status','event']].value_counts()"
   ]
  },
  {
   "source": [
    " ## For everything we assume the next event\n",
    "we have to account for what can happen: \n",
    "* Shot: \n",
    "    * Puck Recovery\n",
    "    * Shot: Rebound \n",
    "    * Faceoff Win: Out of Play or Goalie froze the puck \n",
    "    * Goal: Rebound \n",
    "    * Penalty Taken \n",
    "    * Play: Pass from Rebound \n",
    "    * Incomplete Play: Pass from Rebound \n",
    "    * Dump in/out: surrender the puck from rebound\n",
    "*  Dump In/Out: \n",
    "    * Puck Recovery\n",
    "    * Zone Entry\n",
    "    * Faceoff Win: Goalie Freeze, icing \n",
    "    * Penalty Taken \n",
    "* Zone Entry Dump:\n",
    "    * Puck Recovery \n",
    "    * Faceoff Win: Icing or over the glass.\n",
    "    * Penalty Taken \n",
    "    \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Strength States: differences between team Strengths "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       " 0.0    39618\n",
       " 1.0     8113\n",
       "-1.0     2755\n",
       " 2.0      350\n",
       "-2.0       48\n",
       "Name: strength_state, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"womens.loc[womens['team']==womens['home_team'],'strength_state'] = womens.loc[womens['team']==womens['home_team'],'home_team_skaters'].sub(womens.loc[womens['team']==womens['home_team'],'away_team_skaters'])\\nwomens.loc[womens['team']==womens['away_team'],'strength_state'] = womens.loc[womens['team']==womens['away_team'],'away_team_skaters'].sub(womens.loc[womens['team']==womens['away_team'],'home_team_skaters'])\\nwomens['strength_state'].value_counts()\";\n                var nbb_formatted_code = \"womens.loc[womens[\\\"team\\\"] == womens[\\\"home_team\\\"], \\\"strength_state\\\"] = womens.loc[\\n    womens[\\\"team\\\"] == womens[\\\"home_team\\\"], \\\"home_team_skaters\\\"\\n].sub(womens.loc[womens[\\\"team\\\"] == womens[\\\"home_team\\\"], \\\"away_team_skaters\\\"])\\nwomens.loc[womens[\\\"team\\\"] == womens[\\\"away_team\\\"], \\\"strength_state\\\"] = womens.loc[\\n    womens[\\\"team\\\"] == womens[\\\"away_team\\\"], \\\"away_team_skaters\\\"\\n].sub(womens.loc[womens[\\\"team\\\"] == womens[\\\"away_team\\\"], \\\"home_team_skaters\\\"])\\nwomens[\\\"strength_state\\\"].value_counts()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens.loc[womens['team']==womens['home_team'],'strength_state'] = womens.loc[womens['team']==womens['home_team'],'home_team_skaters'].sub(womens.loc[womens['team']==womens['home_team'],'away_team_skaters'])\n",
    "womens.loc[womens['team']==womens['away_team'],'strength_state'] = womens.loc[womens['team']==womens['away_team'],'away_team_skaters'].sub(womens.loc[womens['team']==womens['away_team'],'home_team_skaters'])\n",
    "womens['strength_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5    23164\n",
       "4     2109\n",
       "6      137\n",
       "3       38\n",
       "Name: home_team_skaters, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"womens.loc[womens['team']==womens['home_team'],'home_team_skaters'].value_counts(dropna=False)\";\n                var nbb_formatted_code = \"womens.loc[womens[\\\"team\\\"] == womens[\\\"home_team\\\"], \\\"home_team_skaters\\\"].value_counts(\\n    dropna=False\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens.loc[womens['team']==womens['home_team'],'home_team_skaters'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 8
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"womens.loc[50883,'home_team_skaters']\";\n                var nbb_formatted_code = \"womens.loc[50883, \\\"home_team_skaters\\\"]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens.loc[50883,'home_team_skaters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['game_date', 'home_team', 'away_team', 'period', 'clock',\n",
       "       'home_team_skaters', 'away_team_skaters', 'home_team_goals',\n",
       "       'away_team_goals', 'team', 'player', 'event', 'x_coord', 'y_coord',\n",
       "       'detail_1', 'detail_2', 'detail_3', 'detail_4', 'player_2', 'x_coord_2',\n",
       "       'y_coord_2', 'game_id', 'is_home', 'is_shot', 'is_goal', 'event_id',\n",
       "       'team_id', 'player_id', 'detail_1_code', 'detail_2_code',\n",
       "       'detail_3_code', 'detail_4_code', 'goal_diff', 'seconds_remaining',\n",
       "       'poss_status', 'strength_state'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"womens.columns\";\n                var nbb_formatted_code = \"womens.columns\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens.columns"
   ]
  },
  {
   "source": [
    "#  Calculate differences in disctance for actions\n",
    "## create endpoint for actions\n",
    "### Shot\n",
    "* on net: position of the goal\n",
    "* missed/blocked possesion lost or Retained: location next event -> Puck Recovery\n",
    "### Goal \n",
    "* position of the goal\n",
    "### Takeaway\n",
    "* same position\n",
    "### Puck Recovery\n",
    "* same position\n",
    "### Dump In/Out\n",
    "* Possession Lost or Retained: location of the next event (Puck Recovery)\n",
    "### Zone Entry\n",
    "* Carried: same position\n",
    "* Dumped: location of the next event (Puck Recovery)\n",
    "* Passed: entpoint of the pass\n",
    "### Faceoff Wins\n",
    "* same position\n",
    "### Penalty Taken\n",
    "* same position"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"womens.loc[(womens['event']=='Shot') & (womens['detail_2'] == 'On Net'),['x_coord_2','y_coord_2']] = [GOAL_X,GOAL_Y]\\nshifted_coords = womens.loc[:,['x_coord','y_coord']].shift(-1)\\nwomens2 = womens.loc[:]\\nwomens2.loc[:,['x_coord','y_coord']] = shifted_coords\\nwomens.loc[(womens['event']=='Shot') & (womens['detail_2'] == 'Blocked'),'x_coord_2'] = womens2.loc[(womens2['event']=='Shot') & (womens2['detail_2'] == 'Blocked'),'x_coord']\\nwomens.loc[(womens['event']=='Shot') & (womens['detail_2'] == 'Blocked'),'y_coord_2'] = womens2.loc[(womens2['event']=='Shot') & (womens2['detail_2'] == 'Blocked'),'y_coord']\\nwomens.loc[(womens['event']=='Shot') & (womens['detail_2'] == 'Missed'),'x_coord_2'] = womens2.loc[(womens2['event']=='Shot') & (womens2['detail_2'] == 'Missed'),'x_coord']\\nwomens.loc[(womens['event']=='Shot') & (womens['detail_2'] == 'Missed'),'y_coord_2'] = womens2.loc[(womens2['event']=='Shot') & (womens2['detail_2'] == 'Missed'),'y_coord']\\nwomens.loc[womens['event']=='Goal',['x_coord_2','y_coord_2']] = [GOAL_X,GOAL_Y]\\nwomens.loc[womens['event']=='Takeaway','x_coord_2'] = womens.loc[womens['event']=='Takeaway','x_coord']\\nwomens.loc[womens['event']=='Takeaway','y_coord_2'] = womens.loc[womens['event']=='Takeaway','y_coord']\\nwomens.loc[womens['event']=='Puck Recovery','x_coord_2'] = womens.loc[womens['event']=='Puck Recovery','x_coord']\\nwomens.loc[womens['event']=='Puck Recovery','y_coord_2'] = womens.loc[womens['event']=='Puck Recovery','y_coord']\\nwomens.loc[womens['event']=='Dump In/Out','x_coord_2'] = womens2.loc[womens2['event']=='Dump In/Out','x_coord']\\nwomens.loc[womens['event']=='Dump In/Out','y_coord_2'] = womens2.loc[womens2['event']=='Dump In/Out','y_coord']\\nwomens.loc[womens['event']=='Zone Entry','x_coord_2'] = womens.loc[womens['event']=='Zone Entry','x_coord']\\nwomens.loc[womens['event']=='Zone Entry','y_coord_2'] = womens.loc[womens['event']=='Zone Entry','y_coord']\\nwomens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped'),'x_coord_2'] = womens2.loc[(womens2['event']=='Zone Entry') & (womens2['detail_1']=='Dumped'),'x_coord']\\nwomens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped'),'y_coord_2'] = womens2.loc[(womens2['event']=='Zone Entry') & (womens2['detail_1']=='Dumped'),'y_coord']\\nwomens.loc[womens['event']=='Faceoff Win','x_coord_2'] = womens.loc[womens['event']=='Faceoff Win','x_coord']\\nwomens.loc[womens['event']=='Faceoff Win','y_coord_2'] = womens.loc[womens['event']=='Faceoff Win','y_coord']\\nwomens.loc[womens['event']=='Penalty Taken','x_coord_2'] = womens.loc[womens['event']=='Penalty Taken','x_coord']\\nwomens.loc[womens['event']=='Penalty Taken','y_coord_2'] = womens.loc[womens['event']=='Penalty Taken','y_coord']\";\n                var nbb_formatted_code = \"womens.loc[\\n    (womens[\\\"event\\\"] == \\\"Shot\\\") & (womens[\\\"detail_2\\\"] == \\\"On Net\\\"),\\n    [\\\"x_coord_2\\\", \\\"y_coord_2\\\"],\\n] = [GOAL_X, GOAL_Y]\\nshifted_coords = womens.loc[:, [\\\"x_coord\\\", \\\"y_coord\\\"]].shift(-1)\\nwomens2 = womens.loc[:]\\nwomens2.loc[:, [\\\"x_coord\\\", \\\"y_coord\\\"]] = shifted_coords\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Shot\\\") & (womens[\\\"detail_2\\\"] == \\\"Blocked\\\"), \\\"x_coord_2\\\"\\n] = womens2.loc[\\n    (womens2[\\\"event\\\"] == \\\"Shot\\\") & (womens2[\\\"detail_2\\\"] == \\\"Blocked\\\"), \\\"x_coord\\\"\\n]\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Shot\\\") & (womens[\\\"detail_2\\\"] == \\\"Blocked\\\"), \\\"y_coord_2\\\"\\n] = womens2.loc[\\n    (womens2[\\\"event\\\"] == \\\"Shot\\\") & (womens2[\\\"detail_2\\\"] == \\\"Blocked\\\"), \\\"y_coord\\\"\\n]\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Shot\\\") & (womens[\\\"detail_2\\\"] == \\\"Missed\\\"), \\\"x_coord_2\\\"\\n] = womens2.loc[\\n    (womens2[\\\"event\\\"] == \\\"Shot\\\") & (womens2[\\\"detail_2\\\"] == \\\"Missed\\\"), \\\"x_coord\\\"\\n]\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Shot\\\") & (womens[\\\"detail_2\\\"] == \\\"Missed\\\"), \\\"y_coord_2\\\"\\n] = womens2.loc[\\n    (womens2[\\\"event\\\"] == \\\"Shot\\\") & (womens2[\\\"detail_2\\\"] == \\\"Missed\\\"), \\\"y_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Goal\\\", [\\\"x_coord_2\\\", \\\"y_coord_2\\\"]] = [GOAL_X, GOAL_Y]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Takeaway\\\", \\\"x_coord_2\\\"] = womens.loc[\\n    womens[\\\"event\\\"] == \\\"Takeaway\\\", \\\"x_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Takeaway\\\", \\\"y_coord_2\\\"] = womens.loc[\\n    womens[\\\"event\\\"] == \\\"Takeaway\\\", \\\"y_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Puck Recovery\\\", \\\"x_coord_2\\\"] = womens.loc[\\n    womens[\\\"event\\\"] == \\\"Puck Recovery\\\", \\\"x_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Puck Recovery\\\", \\\"y_coord_2\\\"] = womens.loc[\\n    womens[\\\"event\\\"] == \\\"Puck Recovery\\\", \\\"y_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Dump In/Out\\\", \\\"x_coord_2\\\"] = womens2.loc[\\n    womens2[\\\"event\\\"] == \\\"Dump In/Out\\\", \\\"x_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Dump In/Out\\\", \\\"y_coord_2\\\"] = womens2.loc[\\n    womens2[\\\"event\\\"] == \\\"Dump In/Out\\\", \\\"y_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Zone Entry\\\", \\\"x_coord_2\\\"] = womens.loc[\\n    womens[\\\"event\\\"] == \\\"Zone Entry\\\", \\\"x_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Zone Entry\\\", \\\"y_coord_2\\\"] = womens.loc[\\n    womens[\\\"event\\\"] == \\\"Zone Entry\\\", \\\"y_coord\\\"\\n]\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Zone Entry\\\") & (womens[\\\"detail_1\\\"] == \\\"Dumped\\\"), \\\"x_coord_2\\\"\\n] = womens2.loc[\\n    (womens2[\\\"event\\\"] == \\\"Zone Entry\\\") & (womens2[\\\"detail_1\\\"] == \\\"Dumped\\\"), \\\"x_coord\\\"\\n]\\nwomens.loc[\\n    (womens[\\\"event\\\"] == \\\"Zone Entry\\\") & (womens[\\\"detail_1\\\"] == \\\"Dumped\\\"), \\\"y_coord_2\\\"\\n] = womens2.loc[\\n    (womens2[\\\"event\\\"] == \\\"Zone Entry\\\") & (womens2[\\\"detail_1\\\"] == \\\"Dumped\\\"), \\\"y_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Faceoff Win\\\", \\\"x_coord_2\\\"] = womens.loc[\\n    womens[\\\"event\\\"] == \\\"Faceoff Win\\\", \\\"x_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Faceoff Win\\\", \\\"y_coord_2\\\"] = womens.loc[\\n    womens[\\\"event\\\"] == \\\"Faceoff Win\\\", \\\"y_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Penalty Taken\\\", \\\"x_coord_2\\\"] = womens.loc[\\n    womens[\\\"event\\\"] == \\\"Penalty Taken\\\", \\\"x_coord\\\"\\n]\\nwomens.loc[womens[\\\"event\\\"] == \\\"Penalty Taken\\\", \\\"y_coord_2\\\"] = womens.loc[\\n    womens[\\\"event\\\"] == \\\"Penalty Taken\\\", \\\"y_coord\\\"\\n]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens.loc[(womens['event']=='Shot') & (womens['detail_2'] == 'On Net'),['x_coord_2','y_coord_2']] = [GOAL_X,GOAL_Y]\n",
    "shifted_coords = womens.loc[:,['x_coord','y_coord']].shift(-1)\n",
    "womens2 = womens.loc[:]\n",
    "womens2.loc[:,['x_coord','y_coord']] = shifted_coords\n",
    "womens.loc[(womens['event']=='Shot') & (womens['detail_2'] == 'Blocked'),'x_coord_2'] = womens2.loc[(womens2['event']=='Shot') & (womens2['detail_2'] == 'Blocked'),'x_coord']\n",
    "womens.loc[(womens['event']=='Shot') & (womens['detail_2'] == 'Blocked'),'y_coord_2'] = womens2.loc[(womens2['event']=='Shot') & (womens2['detail_2'] == 'Blocked'),'y_coord']\n",
    "womens.loc[(womens['event']=='Shot') & (womens['detail_2'] == 'Missed'),'x_coord_2'] = womens2.loc[(womens2['event']=='Shot') & (womens2['detail_2'] == 'Missed'),'x_coord']\n",
    "womens.loc[(womens['event']=='Shot') & (womens['detail_2'] == 'Missed'),'y_coord_2'] = womens2.loc[(womens2['event']=='Shot') & (womens2['detail_2'] == 'Missed'),'y_coord']\n",
    "womens.loc[womens['event']=='Goal',['x_coord_2','y_coord_2']] = [GOAL_X,GOAL_Y]\n",
    "womens.loc[womens['event']=='Takeaway','x_coord_2'] = womens.loc[womens['event']=='Takeaway','x_coord']\n",
    "womens.loc[womens['event']=='Takeaway','y_coord_2'] = womens.loc[womens['event']=='Takeaway','y_coord']\n",
    "womens.loc[womens['event']=='Puck Recovery','x_coord_2'] = womens.loc[womens['event']=='Puck Recovery','x_coord']\n",
    "womens.loc[womens['event']=='Puck Recovery','y_coord_2'] = womens.loc[womens['event']=='Puck Recovery','y_coord']\n",
    "womens.loc[womens['event']=='Dump In/Out','x_coord_2'] = womens2.loc[womens2['event']=='Dump In/Out','x_coord']\n",
    "womens.loc[womens['event']=='Dump In/Out','y_coord_2'] = womens2.loc[womens2['event']=='Dump In/Out','y_coord']\n",
    "womens.loc[womens['event']=='Zone Entry','x_coord_2'] = womens.loc[womens['event']=='Zone Entry','x_coord']\n",
    "womens.loc[womens['event']=='Zone Entry','y_coord_2'] = womens.loc[womens['event']=='Zone Entry','y_coord']\n",
    "womens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped'),'x_coord_2'] = womens2.loc[(womens2['event']=='Zone Entry') & (womens2['detail_1']=='Dumped'),'x_coord']\n",
    "womens.loc[(womens['event']=='Zone Entry') & (womens['detail_1']=='Dumped'),'y_coord_2'] = womens2.loc[(womens2['event']=='Zone Entry') & (womens2['detail_1']=='Dumped'),'y_coord']\n",
    "womens.loc[womens['event']=='Faceoff Win','x_coord_2'] = womens.loc[womens['event']=='Faceoff Win','x_coord']\n",
    "womens.loc[womens['event']=='Faceoff Win','y_coord_2'] = womens.loc[womens['event']=='Faceoff Win','y_coord']\n",
    "womens.loc[womens['event']=='Penalty Taken','x_coord_2'] = womens.loc[womens['event']=='Penalty Taken','x_coord']\n",
    "womens.loc[womens['event']=='Penalty Taken','y_coord_2'] = womens.loc[womens['event']=='Penalty Taken','y_coord']"
   ]
  },
  {
   "source": [
    "## make columns for in which zone a player is in and a diff column for it \n",
    "* 1 is the defensive zone \n",
    "* 2 is the neutral zone \n",
    "* 3 is the offensive zone\n",
    "* a positive difference is the difference in zones forward\n",
    "* a negative difference is the differene in zone backwards"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"womens.loc[womens['x_coord'] <= D_ZONE, 'zone_1'] = 1\\nwomens.loc[womens['x_coord'] > D_ZONE, 'zone_1'] = 2\\nwomens.loc[womens['x_coord'] >= O_ZONE, 'zone_1'] = 3\\nwomens.loc[womens['x_coord_2'] <= D_ZONE, 'zone_2'] = 1\\nwomens.loc[womens['x_coord_2'] > D_ZONE, 'zone_2'] = 2\\nwomens.loc[womens['x_coord_2'] >= O_ZONE, 'zone_2'] = 3\\nwomens.loc[womens['event']=='Zone Entry','zone_1'] = 2\\nwomens.loc[womens['event']=='Zone Entry','zone_2'] = 3\\nwomens.loc[:,'zone_diff'] = womens['zone_2'] - womens['zone_1']\";\n                var nbb_formatted_code = \"womens.loc[womens[\\\"x_coord\\\"] <= D_ZONE, \\\"zone_1\\\"] = 1\\nwomens.loc[womens[\\\"x_coord\\\"] > D_ZONE, \\\"zone_1\\\"] = 2\\nwomens.loc[womens[\\\"x_coord\\\"] >= O_ZONE, \\\"zone_1\\\"] = 3\\nwomens.loc[womens[\\\"x_coord_2\\\"] <= D_ZONE, \\\"zone_2\\\"] = 1\\nwomens.loc[womens[\\\"x_coord_2\\\"] > D_ZONE, \\\"zone_2\\\"] = 2\\nwomens.loc[womens[\\\"x_coord_2\\\"] >= O_ZONE, \\\"zone_2\\\"] = 3\\nwomens.loc[womens[\\\"event\\\"] == \\\"Zone Entry\\\", \\\"zone_1\\\"] = 2\\nwomens.loc[womens[\\\"event\\\"] == \\\"Zone Entry\\\", \\\"zone_2\\\"] = 3\\nwomens.loc[:, \\\"zone_diff\\\"] = womens[\\\"zone_2\\\"] - womens[\\\"zone_1\\\"]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens.loc[womens['x_coord'] <= D_ZONE, 'zone_1'] = 1\n",
    "womens.loc[womens['x_coord'] > D_ZONE, 'zone_1'] = 2\n",
    "womens.loc[womens['x_coord'] >= O_ZONE, 'zone_1'] = 3\n",
    "womens.loc[womens['x_coord_2'] <= D_ZONE, 'zone_2'] = 1\n",
    "womens.loc[womens['x_coord_2'] > D_ZONE, 'zone_2'] = 2\n",
    "womens.loc[womens['x_coord_2'] >= O_ZONE, 'zone_2'] = 3\n",
    "womens.loc[womens['event']=='Zone Entry','zone_1'] = 2\n",
    "womens.loc[womens['event']=='Zone Entry','zone_2'] = 3\n",
    "womens.loc[:,'zone_diff'] = womens['zone_2'] - womens['zone_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       " 0.0    41378\n",
       " 1.0     7089\n",
       "-2.0      975\n",
       "-1.0      829\n",
       " 2.0      613\n",
       "Name: zone_diff, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"womens['zone_diff'].value_counts()\";\n                var nbb_formatted_code = \"womens[\\\"zone_diff\\\"].value_counts()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens['zone_diff'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"diff_x1 = GOAL_X - womens['x_coord']\\ndiff_y1 = abs(GOAL_Y - womens['y_coord'])\\ndiff_x2 = GOAL_X - womens['x_coord_2']\\ndiff_y2 = abs(GOAL_Y - womens['y_coord_2'])\\nwomens['start_distance_to_goal'] = np.sqrt(diff_x1 ** 2 + diff_y1 ** 2)\\nwomens['end_distance_to_goal'] = np.sqrt(diff_x2 ** 2 + diff_y2 ** 2)\\nwomens['diff_x'] = womens['x_coord_2'] - womens['x_coord']\\nwomens['diff_y'] = womens['y_coord_2'] - womens['y_coord']\\nwomens['distance_covered'] = np.sqrt((womens['x_coord_2'] - womens['x_coord']) ** 2 + (womens['y_coord_2'] - womens['y_coord']) ** 2)\\ndiff_x1 = diff_x1.astype(float)\\nwomens['angle_to_goal_start'] = np.divide(diff_x1, diff_y1,out=np.zeros_like(diff_x1),where=(diff_y1 != 0))\\nwomens.loc[womens['angle_to_goal_start']>=360,'angle_to_goal_start'] = womens.loc[womens['angle_to_goal_start'] >=360,'angle_to_goal_start'] - 360\\nwomens.loc[womens['angle_to_goal_start']< 0,'angle_to_goal_start'] = womens.loc[womens['angle_to_goal_start'] < 0,'angle_to_goal_start'] + 360\\ndiff_x2 = diff_x2.astype(float)\\nwomens['angle_to_goal_end'] = np.divide(diff_x2, diff_y2,out=np.zeros_like(diff_x2),where=(diff_y2 != 0))\\nwomens.loc[womens['angle_to_goal_end']>=360,'angle_to_goal_end'] = womens.loc[womens['angle_to_goal_end'] >=360,'angle_to_goal_end'] - 360\\nwomens.loc[womens['angle_to_goal_end']< 0,'angle_to_goal_end'] = womens.loc[womens['angle_to_goal_end'] < 0,'angle_to_goal_end'] + 360\\nwomens['diff_angle_to_goal'] = womens['angle_to_goal_end'] - womens['angle_to_goal_start']\";\n                var nbb_formatted_code = \"diff_x1 = GOAL_X - womens[\\\"x_coord\\\"]\\ndiff_y1 = abs(GOAL_Y - womens[\\\"y_coord\\\"])\\ndiff_x2 = GOAL_X - womens[\\\"x_coord_2\\\"]\\ndiff_y2 = abs(GOAL_Y - womens[\\\"y_coord_2\\\"])\\nwomens[\\\"start_distance_to_goal\\\"] = np.sqrt(diff_x1 ** 2 + diff_y1 ** 2)\\nwomens[\\\"end_distance_to_goal\\\"] = np.sqrt(diff_x2 ** 2 + diff_y2 ** 2)\\nwomens[\\\"diff_x\\\"] = womens[\\\"x_coord_2\\\"] - womens[\\\"x_coord\\\"]\\nwomens[\\\"diff_y\\\"] = womens[\\\"y_coord_2\\\"] - womens[\\\"y_coord\\\"]\\nwomens[\\\"distance_covered\\\"] = np.sqrt(\\n    (womens[\\\"x_coord_2\\\"] - womens[\\\"x_coord\\\"]) ** 2\\n    + (womens[\\\"y_coord_2\\\"] - womens[\\\"y_coord\\\"]) ** 2\\n)\\ndiff_x1 = diff_x1.astype(float)\\nwomens[\\\"angle_to_goal_start\\\"] = np.divide(\\n    diff_x1, diff_y1, out=np.zeros_like(diff_x1), where=(diff_y1 != 0)\\n)\\nwomens.loc[womens[\\\"angle_to_goal_start\\\"] >= 360, \\\"angle_to_goal_start\\\"] = (\\n    womens.loc[womens[\\\"angle_to_goal_start\\\"] >= 360, \\\"angle_to_goal_start\\\"] - 360\\n)\\nwomens.loc[womens[\\\"angle_to_goal_start\\\"] < 0, \\\"angle_to_goal_start\\\"] = (\\n    womens.loc[womens[\\\"angle_to_goal_start\\\"] < 0, \\\"angle_to_goal_start\\\"] + 360\\n)\\ndiff_x2 = diff_x2.astype(float)\\nwomens[\\\"angle_to_goal_end\\\"] = np.divide(\\n    diff_x2, diff_y2, out=np.zeros_like(diff_x2), where=(diff_y2 != 0)\\n)\\nwomens.loc[womens[\\\"angle_to_goal_end\\\"] >= 360, \\\"angle_to_goal_end\\\"] = (\\n    womens.loc[womens[\\\"angle_to_goal_end\\\"] >= 360, \\\"angle_to_goal_end\\\"] - 360\\n)\\nwomens.loc[womens[\\\"angle_to_goal_end\\\"] < 0, \\\"angle_to_goal_end\\\"] = (\\n    womens.loc[womens[\\\"angle_to_goal_end\\\"] < 0, \\\"angle_to_goal_end\\\"] + 360\\n)\\nwomens[\\\"diff_angle_to_goal\\\"] = (\\n    womens[\\\"angle_to_goal_end\\\"] - womens[\\\"angle_to_goal_start\\\"]\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "diff_x1 = GOAL_X - womens['x_coord']\n",
    "diff_y1 = abs(GOAL_Y - womens['y_coord'])\n",
    "diff_x2 = GOAL_X - womens['x_coord_2']\n",
    "diff_y2 = abs(GOAL_Y - womens['y_coord_2'])\n",
    "womens['start_distance_to_goal'] = np.sqrt(diff_x1 ** 2 + diff_y1 ** 2)\n",
    "womens['end_distance_to_goal'] = np.sqrt(diff_x2 ** 2 + diff_y2 ** 2)\n",
    "womens['diff_x'] = womens['x_coord_2'] - womens['x_coord']\n",
    "womens['diff_y'] = womens['y_coord_2'] - womens['y_coord']\n",
    "womens['distance_covered'] = np.sqrt((womens['x_coord_2'] - womens['x_coord']) ** 2 + (womens['y_coord_2'] - womens['y_coord']) ** 2)\n",
    "diff_x1 = diff_x1.astype(float)\n",
    "womens['angle_to_goal_start'] = np.divide(diff_x1, diff_y1,out=np.zeros_like(diff_x1),where=(diff_y1 != 0))\n",
    "womens.loc[womens['angle_to_goal_start']>=360,'angle_to_goal_start'] = womens.loc[womens['angle_to_goal_start'] >=360,'angle_to_goal_start'] - 360\n",
    "womens.loc[womens['angle_to_goal_start']< 0,'angle_to_goal_start'] = womens.loc[womens['angle_to_goal_start'] < 0,'angle_to_goal_start'] + 360\n",
    "diff_x2 = diff_x2.astype(float)\n",
    "womens['angle_to_goal_end'] = np.divide(diff_x2, diff_y2,out=np.zeros_like(diff_x2),where=(diff_y2 != 0))\n",
    "womens.loc[womens['angle_to_goal_end']>=360,'angle_to_goal_end'] = womens.loc[womens['angle_to_goal_end'] >=360,'angle_to_goal_end'] - 360\n",
    "womens.loc[womens['angle_to_goal_end']< 0,'angle_to_goal_end'] = womens.loc[womens['angle_to_goal_end'] < 0,'angle_to_goal_end'] + 360\n",
    "womens['diff_angle_to_goal'] = womens['angle_to_goal_end'] - womens['angle_to_goal_start']"
   ]
  },
  {
   "source": [
    "# non-shot xG models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"xg_features = ['x_coord','y_coord','start_distance_to_goal','angle_to_goal_start','strength_state']\\nxg_labels = ['is_goal']\";\n                var nbb_formatted_code = \"xg_features = [\\n    \\\"x_coord\\\",\\n    \\\"y_coord\\\",\\n    \\\"start_distance_to_goal\\\",\\n    \\\"angle_to_goal_start\\\",\\n    \\\"strength_state\\\",\\n]\\nxg_labels = [\\\"is_goal\\\"]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "xg_features = ['x_coord','y_coord','start_distance_to_goal','angle_to_goal_start','strength_state']\n",
    "xg_labels = ['is_goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "arning_rate=0.01, max_depth=3, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   3.0s\n",
      "[13:44:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   2.9s\n",
      "[13:44:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   2.9s\n",
      "[13:44:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   3.0s\n",
      "[13:44:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.3s\n",
      "[13:44:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.3s\n",
      "[13:44:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.3s\n",
      "[13:44:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.3s\n",
      "[13:44:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.3s\n",
      "[13:44:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   1.7s\n",
      "[13:44:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   1.7s\n",
      "[13:44:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   1.6s\n",
      "[13:44:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   1.7s\n",
      "[13:44:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   1.7s\n",
      "[13:44:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   3.5s\n",
      "[13:44:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   3.6s\n",
      "[13:44:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   3.4s\n",
      "[13:45:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   3.5s\n",
      "[13:45:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   3.5s\n",
      "[13:45:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.4s\n",
      "[13:45:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.3s\n",
      "[13:45:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.4s\n",
      "[13:45:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.3s\n",
      "[13:45:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.3s\n",
      "[13:45:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   1.8s\n",
      "[13:45:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   1.8s\n",
      "[13:45:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   1.8s\n",
      "[13:45:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   1.9s\n",
      "[13:45:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   1.9s\n",
      "[13:45:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   4.0s\n",
      "[13:45:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   4.0s\n",
      "[13:45:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   3.9s\n",
      "[13:45:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   4.0s\n",
      "[13:45:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   4.0s\n",
      "[13:45:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.4s\n",
      "[13:45:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.4s\n",
      "[13:45:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.4s\n",
      "[13:45:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.4s\n",
      "[13:45:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, nthread=4, objective=binary:logistic, seed=42; total time=   0.4s\n",
      "[13:45:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   2.1s\n",
      "[13:45:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   2.1s\n",
      "[13:45:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   2.1s\n",
      "[13:45:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   2.2s\n",
      "[13:45:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, nthread=4, objective=binary:logistic, seed=42; total time=   2.4s\n",
      "[13:45:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   4.9s\n",
      "[13:45:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   4.6s\n",
      "[13:46:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   4.5s\n",
      "[13:46:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   4.6s\n",
      "[13:46:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=1000, nthread=4, objective=binary:logistic, seed=42; total time=   4.6s\n",
      "[13:46:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"parameters = {\\n    'nthread': [4],\\n    'objective': ['binary:logistic'],\\n    'max_depth': [3, 4, 5, 6],\\n    'learning_rate': [0.01],\\n    'n_estimators': [100, 500, 1000],\\n    'seed': [42]\\n    }\\n\\ndf_xg_model = pd.DataFrame()\\nkf = KFold(10, shuffle=True)\\n\\nfor train_idx, test_idx in kf.split(womens):\\n    train_data = womens.iloc[train_idx].copy()\\n    test_data = womens.iloc[test_idx].copy()\\n\\n    classifier = XGBClassifier()\\n    classifier = GridSearchCV(classifier, parameters, scoring='roc_auc', verbose=2)\\n    classifier.fit(\\n        train_data[xg_features],\\n        train_data[xg_labels]\\n    )\\n    dfs_predictions = {}\\n    y_pred = classifier.predict_proba(test_data[xg_features])\\n    dfs_predictions[xg_labels[0]] = pd.Series(y_pred[:,1], index=test_data.index)\\n    df_predictions = pd.concat(dfs_predictions, axis=1)\\n    df_xg_model = df_xg_model.append(df_predictions)\";\n                var nbb_formatted_code = \"parameters = {\\n    \\\"nthread\\\": [4],\\n    \\\"objective\\\": [\\\"binary:logistic\\\"],\\n    \\\"max_depth\\\": [3, 4, 5, 6],\\n    \\\"learning_rate\\\": [0.01],\\n    \\\"n_estimators\\\": [100, 500, 1000],\\n    \\\"seed\\\": [42],\\n}\\n\\ndf_xg_model = pd.DataFrame()\\nkf = KFold(10, shuffle=True)\\n\\nfor train_idx, test_idx in kf.split(womens):\\n    train_data = womens.iloc[train_idx].copy()\\n    test_data = womens.iloc[test_idx].copy()\\n\\n    classifier = XGBClassifier()\\n    classifier = GridSearchCV(classifier, parameters, scoring=\\\"roc_auc\\\", verbose=2)\\n    classifier.fit(train_data[xg_features], train_data[xg_labels])\\n    dfs_predictions = {}\\n    y_pred = classifier.predict_proba(test_data[xg_features])\\n    dfs_predictions[xg_labels[0]] = pd.Series(y_pred[:, 1], index=test_data.index)\\n    df_predictions = pd.concat(dfs_predictions, axis=1)\\n    df_xg_model = df_xg_model.append(df_predictions)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "parameters = {\n",
    "    'nthread': [4],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'seed': [42]\n",
    "    }\n",
    "\n",
    "df_xg_model = pd.DataFrame()\n",
    "kf = KFold(10, shuffle=True)\n",
    "\n",
    "for train_idx, test_idx in kf.split(womens):\n",
    "    train_data = womens.iloc[train_idx].copy()\n",
    "    test_data = womens.iloc[test_idx].copy()\n",
    "\n",
    "    classifier = XGBClassifier()\n",
    "    classifier = GridSearchCV(classifier, parameters, scoring='roc_auc', verbose=2)\n",
    "    classifier.fit(\n",
    "        train_data[xg_features],\n",
    "        train_data[xg_labels]\n",
    "    )\n",
    "    dfs_predictions = {}\n",
    "    y_pred = classifier.predict_proba(test_data[xg_features])\n",
    "    dfs_predictions[xg_labels[0]] = pd.Series(y_pred[:,1], index=test_data.index)\n",
    "    df_predictions = pd.concat(dfs_predictions, axis=1)\n",
    "    df_xg_model = df_xg_model.append(df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "metadata": {},
     "execution_count": 16
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"womens['is_goal'].sum()\";\n                var nbb_formatted_code = \"womens[\\\"is_goal\\\"].sum()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens['is_goal'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "is_goal    133.816666\n",
       "dtype: float32"
      ]
     },
     "metadata": {},
     "execution_count": 17
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"df_xg_model.sum()\";\n                var nbb_formatted_code = \"df_xg_model.sum()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "df_xg_model.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "is_goal    1.816666\n",
       "dtype: float32"
      ]
     },
     "metadata": {},
     "execution_count": 18
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"abs(df_xg_model.sum() - womens['is_goal'].sum())\";\n                var nbb_formatted_code = \"abs(df_xg_model.sum() - womens[\\\"is_goal\\\"].sum())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "abs(df_xg_model.sum() - womens['is_goal'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"womens['non_shot_xg'] = df_xg_model['is_goal']\";\n                var nbb_formatted_code = \"womens[\\\"non_shot_xg\\\"] = df_xg_model[\\\"is_goal\\\"]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens['non_shot_xg'] = df_xg_model['is_goal']"
   ]
  },
  {
   "source": [
    "# create Labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 20;\n                var nbb_unformatted_code = \"goals = womens['event'].str.contains('Goal')\\ny = pd.concat([womens.loc[:, 'is_goal'], womens.loc[:,'team_id']], axis = 1)\\ny.columns = ['goal','team_id']\\nfor i in range(1, 10):\\n    for col in ['team_id', 'goal']:\\n        shifted = y[col].shift(-i)\\n        shifted[-i:] = y[col][len(y) - 1]\\n        y[f'{col}+{i}'] = shifted.astype(int)\\n\\nscores = y['goal']\\nconcedes = y['goal']\\nfor i in range(1, 10):\\n    goal_scored = y[f'goal+{i}'] & (y[f'team_id+{i}'] == y['team_id'])\\n    goal_opponent = y[f'goal+{i}'] & (y[f'team_id+{i}'] != y['team_id'])\\n    scores = scores | goal_scored\\n    concedes = concedes | goal_opponent\\nlabel_scores = pd.DataFrame(scores, columns=['scores'])\\nlabel_concedes = pd.DataFrame(concedes, columns=['concedes'])\\ndf_labels = pd.concat([label_scores, label_concedes], axis=1)\";\n                var nbb_formatted_code = \"goals = womens[\\\"event\\\"].str.contains(\\\"Goal\\\")\\ny = pd.concat([womens.loc[:, \\\"is_goal\\\"], womens.loc[:, \\\"team_id\\\"]], axis=1)\\ny.columns = [\\\"goal\\\", \\\"team_id\\\"]\\nfor i in range(1, 10):\\n    for col in [\\\"team_id\\\", \\\"goal\\\"]:\\n        shifted = y[col].shift(-i)\\n        shifted[-i:] = y[col][len(y) - 1]\\n        y[f\\\"{col}+{i}\\\"] = shifted.astype(int)\\n\\nscores = y[\\\"goal\\\"]\\nconcedes = y[\\\"goal\\\"]\\nfor i in range(1, 10):\\n    goal_scored = y[f\\\"goal+{i}\\\"] & (y[f\\\"team_id+{i}\\\"] == y[\\\"team_id\\\"])\\n    goal_opponent = y[f\\\"goal+{i}\\\"] & (y[f\\\"team_id+{i}\\\"] != y[\\\"team_id\\\"])\\n    scores = scores | goal_scored\\n    concedes = concedes | goal_opponent\\nlabel_scores = pd.DataFrame(scores, columns=[\\\"scores\\\"])\\nlabel_concedes = pd.DataFrame(concedes, columns=[\\\"concedes\\\"])\\ndf_labels = pd.concat([label_scores, label_concedes], axis=1)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "goals = womens['event'].str.contains('Goal')\n",
    "y = pd.concat([womens.loc[:, 'is_goal'], womens.loc[:,'team_id']], axis = 1)\n",
    "y.columns = ['goal','team_id']\n",
    "for i in range(1, 10):\n",
    "    for col in ['team_id', 'goal']:\n",
    "        shifted = y[col].shift(-i)\n",
    "        shifted[-i:] = y[col][len(y) - 1]\n",
    "        y[f'{col}+{i}'] = shifted.astype(int)\n",
    "\n",
    "scores = y['goal']\n",
    "concedes = y['goal']\n",
    "for i in range(1, 10):\n",
    "    goal_scored = y[f'goal+{i}'] & (y[f'team_id+{i}'] == y['team_id'])\n",
    "    goal_opponent = y[f'goal+{i}'] & (y[f'team_id+{i}'] != y['team_id'])\n",
    "    scores = scores | goal_scored\n",
    "    concedes = concedes | goal_opponent\n",
    "label_scores = pd.DataFrame(scores, columns=['scores'])\n",
    "label_concedes = pd.DataFrame(concedes, columns=['concedes'])\n",
    "df_labels = pd.concat([label_scores, label_concedes], axis=1)"
   ]
  },
  {
   "source": [
    "# Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 21;\n                var nbb_unformatted_code = \"features = ['game_id','team_id', 'player_id', 'period', 'x_coord', 'y_coord', 'x_coord_2',\\n       'y_coord_2', 'is_home', 'is_shot', 'is_goal', 'event_id',\\n       'goal_diff', 'seconds_remaining','diff_x', 'diff_y', 'distance_covered', 'start_distance_to_goal', 'end_distance_to_goal','zone_diff','poss_status','diff_angle_to_goal','non_shot_xg']\\ndf_delays = [womens[features].shift(step).add_suffix(f'-{step}') for step in range(0,3)]\\ndf_features = pd.concat(df_delays, axis=1)\";\n                var nbb_formatted_code = \"features = [\\n    \\\"game_id\\\",\\n    \\\"team_id\\\",\\n    \\\"player_id\\\",\\n    \\\"period\\\",\\n    \\\"x_coord\\\",\\n    \\\"y_coord\\\",\\n    \\\"x_coord_2\\\",\\n    \\\"y_coord_2\\\",\\n    \\\"is_home\\\",\\n    \\\"is_shot\\\",\\n    \\\"is_goal\\\",\\n    \\\"event_id\\\",\\n    \\\"goal_diff\\\",\\n    \\\"seconds_remaining\\\",\\n    \\\"diff_x\\\",\\n    \\\"diff_y\\\",\\n    \\\"distance_covered\\\",\\n    \\\"start_distance_to_goal\\\",\\n    \\\"end_distance_to_goal\\\",\\n    \\\"zone_diff\\\",\\n    \\\"poss_status\\\",\\n    \\\"diff_angle_to_goal\\\",\\n    \\\"non_shot_xg\\\",\\n]\\ndf_delays = [\\n    womens[features].shift(step).add_suffix(f\\\"-{step}\\\") for step in range(0, 3)\\n]\\ndf_features = pd.concat(df_delays, axis=1)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "features = ['game_id','team_id', 'player_id', 'period', 'x_coord', 'y_coord', 'x_coord_2',\n",
    "       'y_coord_2', 'is_home', 'is_shot', 'is_goal', 'event_id',\n",
    "       'goal_diff', 'seconds_remaining','diff_x', 'diff_y', 'distance_covered', 'start_distance_to_goal', 'end_distance_to_goal','zone_diff','poss_status','diff_angle_to_goal','non_shot_xg']\n",
    "df_delays = [womens[features].shift(step).add_suffix(f'-{step}') for step in range(0,3)]\n",
    "df_features = pd.concat(df_delays, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 22;\n                var nbb_unformatted_code = \"for step in range(0,3):\\n    df_features[f'team-{step}'] = df_features['team_id-0'] == df_features[f'team_id-{step}']\\n\\nfor step in range(0,3):\\n    df_features.loc[~(df_features[f'team-{step}']),f'x_coord-{step}'] = ICE_LENGTH - df_features[f'x_coord-{step}']\\n    df_features.loc[~(df_features[f'team-{step}']),f'x_coord_2-{step}'] = ICE_LENGTH - df_features[f'x_coord_2-{step}']\\n    df_features.loc[~(df_features[f'team-{step}']),f'y_coord-{step}'] = ICE_WIDTH - df_features[f'y_coord-{step}']\\n    df_features.loc[~(df_features[f'team-{step}']),f'y_coord_2-{step}'] = ICE_WIDTH - df_features[f'y_coord_2-{step}']\";\n                var nbb_formatted_code = \"for step in range(0, 3):\\n    df_features[f\\\"team-{step}\\\"] = (\\n        df_features[\\\"team_id-0\\\"] == df_features[f\\\"team_id-{step}\\\"]\\n    )\\n\\nfor step in range(0, 3):\\n    df_features.loc[~(df_features[f\\\"team-{step}\\\"]), f\\\"x_coord-{step}\\\"] = (\\n        ICE_LENGTH - df_features[f\\\"x_coord-{step}\\\"]\\n    )\\n    df_features.loc[~(df_features[f\\\"team-{step}\\\"]), f\\\"x_coord_2-{step}\\\"] = (\\n        ICE_LENGTH - df_features[f\\\"x_coord_2-{step}\\\"]\\n    )\\n    df_features.loc[~(df_features[f\\\"team-{step}\\\"]), f\\\"y_coord-{step}\\\"] = (\\n        ICE_WIDTH - df_features[f\\\"y_coord-{step}\\\"]\\n    )\\n    df_features.loc[~(df_features[f\\\"team-{step}\\\"]), f\\\"y_coord_2-{step}\\\"] = (\\n        ICE_WIDTH - df_features[f\\\"y_coord_2-{step}\\\"]\\n    )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "for step in range(0,3):\n",
    "    df_features[f'team-{step}'] = df_features['team_id-0'] == df_features[f'team_id-{step}']\n",
    "\n",
    "for step in range(0,3):\n",
    "    df_features.loc[~(df_features[f'team-{step}']),f'x_coord-{step}'] = ICE_LENGTH - df_features[f'x_coord-{step}']\n",
    "    df_features.loc[~(df_features[f'team-{step}']),f'x_coord_2-{step}'] = ICE_LENGTH - df_features[f'x_coord_2-{step}']\n",
    "    df_features.loc[~(df_features[f'team-{step}']),f'y_coord-{step}'] = ICE_WIDTH - df_features[f'y_coord-{step}']\n",
    "    df_features.loc[~(df_features[f'team-{step}']),f'y_coord_2-{step}'] = ICE_WIDTH - df_features[f'y_coord_2-{step}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 23;\n                var nbb_unformatted_code = \"for step in range(0,3):\\n    start_diff_x = GOAL_X - df_features[f'x_coord-{step}']\\n    start_diff_y = abs(GOAL_Y - df_features[f'y_coord-{step}'])\\n    df_features[f'start_distance_to_goal-{step}'] = np.sqrt(start_diff_x ** 2 + start_diff_y ** 2)\\n    end_diff_x = GOAL_X - df_features[f'x_coord_2-{step}']\\n    end_diff_y = abs(GOAL_Y - df_features[f'y_coord_2-{step}'])\\n    df_features[f'end_distance_to_goal-{step}'] = np.sqrt(end_diff_x ** 2 + end_diff_y ** 2)\\n    df_features[f'diff_x-{step}'] = df_features[f'x_coord_2-{step}'] - df_features[f'x_coord-{step}']\\n    df_features[f'diff_y-{step}'] = df_features[f'y_coord_2-{step}'] - df_features[f'y_coord-{step}']\\n    df_features[f'distance_covered-{step}'] = np.sqrt((df_features[f'x_coord_2-{step}'] - df_features[f'x_coord-{step}']) ** 2 + (df_features[f'y_coord_2-{step}'] - df_features[f'y_coord-{step}']) ** 2)\";\n                var nbb_formatted_code = \"for step in range(0, 3):\\n    start_diff_x = GOAL_X - df_features[f\\\"x_coord-{step}\\\"]\\n    start_diff_y = abs(GOAL_Y - df_features[f\\\"y_coord-{step}\\\"])\\n    df_features[f\\\"start_distance_to_goal-{step}\\\"] = np.sqrt(\\n        start_diff_x ** 2 + start_diff_y ** 2\\n    )\\n    end_diff_x = GOAL_X - df_features[f\\\"x_coord_2-{step}\\\"]\\n    end_diff_y = abs(GOAL_Y - df_features[f\\\"y_coord_2-{step}\\\"])\\n    df_features[f\\\"end_distance_to_goal-{step}\\\"] = np.sqrt(\\n        end_diff_x ** 2 + end_diff_y ** 2\\n    )\\n    df_features[f\\\"diff_x-{step}\\\"] = (\\n        df_features[f\\\"x_coord_2-{step}\\\"] - df_features[f\\\"x_coord-{step}\\\"]\\n    )\\n    df_features[f\\\"diff_y-{step}\\\"] = (\\n        df_features[f\\\"y_coord_2-{step}\\\"] - df_features[f\\\"y_coord-{step}\\\"]\\n    )\\n    df_features[f\\\"distance_covered-{step}\\\"] = np.sqrt(\\n        (df_features[f\\\"x_coord_2-{step}\\\"] - df_features[f\\\"x_coord-{step}\\\"]) ** 2\\n        + (df_features[f\\\"y_coord_2-{step}\\\"] - df_features[f\\\"y_coord-{step}\\\"]) ** 2\\n    )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "for step in range(0,3):\n",
    "    start_diff_x = GOAL_X - df_features[f'x_coord-{step}']\n",
    "    start_diff_y = abs(GOAL_Y - df_features[f'y_coord-{step}'])\n",
    "    df_features[f'start_distance_to_goal-{step}'] = np.sqrt(start_diff_x ** 2 + start_diff_y ** 2)\n",
    "    end_diff_x = GOAL_X - df_features[f'x_coord_2-{step}']\n",
    "    end_diff_y = abs(GOAL_Y - df_features[f'y_coord_2-{step}'])\n",
    "    df_features[f'end_distance_to_goal-{step}'] = np.sqrt(end_diff_x ** 2 + end_diff_y ** 2)\n",
    "    df_features[f'diff_x-{step}'] = df_features[f'x_coord_2-{step}'] - df_features[f'x_coord-{step}']\n",
    "    df_features[f'diff_y-{step}'] = df_features[f'y_coord_2-{step}'] - df_features[f'y_coord-{step}']\n",
    "    df_features[f'distance_covered-{step}'] = np.sqrt((df_features[f'x_coord_2-{step}'] - df_features[f'x_coord-{step}']) ** 2 + (df_features[f'y_coord_2-{step}'] - df_features[f'y_coord-{step}']) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       start_distance_to_goal-0  end_distance_to_goal-0  \\\n",
       "0                     90.001389               90.001389   \n",
       "1                    101.986519              101.986519   \n",
       "2                     92.402651               92.402651   \n",
       "3                     92.402651               46.970736   \n",
       "4                     46.970736               46.970736   \n",
       "...                         ...                     ...   \n",
       "50879                182.937831              182.937831   \n",
       "50880                182.937831              165.774697   \n",
       "50881                161.425679               69.615013   \n",
       "50882                 69.615013               69.615013   \n",
       "50883                 69.615013               50.569259   \n",
       "\n",
       "       start_distance_to_goal-1  end_distance_to_goal-1  \\\n",
       "0                           NaN                     NaN   \n",
       "1                     90.001389               90.001389   \n",
       "2                    101.986519              101.986519   \n",
       "3                     92.402651               92.402651   \n",
       "4                     92.402651               46.970736   \n",
       "...                         ...                     ...   \n",
       "50879                162.059403               18.607794   \n",
       "50880                182.937831              182.937831   \n",
       "50881                182.937831              165.774697   \n",
       "50882                 47.940067              127.930645   \n",
       "50883                 69.615013               69.615013   \n",
       "\n",
       "       start_distance_to_goal-2  end_distance_to_goal-2  team-1  team-2  \n",
       "0                           NaN                     NaN   False   False  \n",
       "1                           NaN                     NaN    True   False  \n",
       "2                     90.001389               90.001389    True    True  \n",
       "3                    101.986519              101.986519    True    True  \n",
       "4                     92.402651               92.402651    True    True  \n",
       "...                         ...                     ...     ...     ...  \n",
       "50879                149.141711              162.059403   False   False  \n",
       "50880                162.059403               18.607794    True   False  \n",
       "50881                182.937831              182.937831    True    True  \n",
       "50882                 18.607794               43.832066   False   False  \n",
       "50883                 47.940067              127.930645    True   False  \n",
       "\n",
       "[50884 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_distance_to_goal-0</th>\n      <th>end_distance_to_goal-0</th>\n      <th>start_distance_to_goal-1</th>\n      <th>end_distance_to_goal-1</th>\n      <th>start_distance_to_goal-2</th>\n      <th>end_distance_to_goal-2</th>\n      <th>team-1</th>\n      <th>team-2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>90.001389</td>\n      <td>90.001389</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>101.986519</td>\n      <td>101.986519</td>\n      <td>90.001389</td>\n      <td>90.001389</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>92.402651</td>\n      <td>92.402651</td>\n      <td>101.986519</td>\n      <td>101.986519</td>\n      <td>90.001389</td>\n      <td>90.001389</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>92.402651</td>\n      <td>46.970736</td>\n      <td>92.402651</td>\n      <td>92.402651</td>\n      <td>101.986519</td>\n      <td>101.986519</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>46.970736</td>\n      <td>46.970736</td>\n      <td>92.402651</td>\n      <td>46.970736</td>\n      <td>92.402651</td>\n      <td>92.402651</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50879</th>\n      <td>182.937831</td>\n      <td>182.937831</td>\n      <td>162.059403</td>\n      <td>18.607794</td>\n      <td>149.141711</td>\n      <td>162.059403</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>50880</th>\n      <td>182.937831</td>\n      <td>165.774697</td>\n      <td>182.937831</td>\n      <td>182.937831</td>\n      <td>162.059403</td>\n      <td>18.607794</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>50881</th>\n      <td>161.425679</td>\n      <td>69.615013</td>\n      <td>182.937831</td>\n      <td>165.774697</td>\n      <td>182.937831</td>\n      <td>182.937831</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>50882</th>\n      <td>69.615013</td>\n      <td>69.615013</td>\n      <td>47.940067</td>\n      <td>127.930645</td>\n      <td>18.607794</td>\n      <td>43.832066</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>50883</th>\n      <td>69.615013</td>\n      <td>50.569259</td>\n      <td>69.615013</td>\n      <td>69.615013</td>\n      <td>47.940067</td>\n      <td>127.930645</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>50884 rows  8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 24;\n                var nbb_unformatted_code = \"df_features['xdiff_sequenc_pre'] = df_features['x_coord-0'] - df_features['x_coord-2']\\ndf_features['ydiff_sequenc_pre'] = df_features['y_coord-0'] - df_features['y_coord-2']\\ndf_features['time_sequence_pre'] = df_features['seconds_remaining-0'] - df_features['seconds_remaining-2']\\ndf_features[['start_distance_to_goal-0', 'end_distance_to_goal-0', 'start_distance_to_goal-1', 'end_distance_to_goal-1', 'start_distance_to_goal-2', 'end_distance_to_goal-2', 'team-1', 'team-2']]\\n            \";\n                var nbb_formatted_code = \"df_features[\\\"xdiff_sequenc_pre\\\"] = df_features[\\\"x_coord-0\\\"] - df_features[\\\"x_coord-2\\\"]\\ndf_features[\\\"ydiff_sequenc_pre\\\"] = df_features[\\\"y_coord-0\\\"] - df_features[\\\"y_coord-2\\\"]\\ndf_features[\\\"time_sequence_pre\\\"] = (\\n    df_features[\\\"seconds_remaining-0\\\"] - df_features[\\\"seconds_remaining-2\\\"]\\n)\\ndf_features[\\n    [\\n        \\\"start_distance_to_goal-0\\\",\\n        \\\"end_distance_to_goal-0\\\",\\n        \\\"start_distance_to_goal-1\\\",\\n        \\\"end_distance_to_goal-1\\\",\\n        \\\"start_distance_to_goal-2\\\",\\n        \\\"end_distance_to_goal-2\\\",\\n        \\\"team-1\\\",\\n        \\\"team-2\\\",\\n    ]\\n]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "df_features['xdiff_sequenc_pre'] = df_features['x_coord-0'] - df_features['x_coord-2']\n",
    "df_features['ydiff_sequenc_pre'] = df_features['y_coord-0'] - df_features['y_coord-2']\n",
    "df_features['time_sequence_pre'] = df_features['seconds_remaining-0'] - df_features['seconds_remaining-2']\n",
    "df_features[['start_distance_to_goal-0', 'end_distance_to_goal-0', 'start_distance_to_goal-1', 'end_distance_to_goal-1', 'start_distance_to_goal-2', 'end_distance_to_goal-2', 'team-1', 'team-2']]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['game_id-0', 'team_id-0', 'player_id-0', 'period-0', 'x_coord-0',\n",
       "       'y_coord-0', 'x_coord_2-0', 'y_coord_2-0', 'is_home-0', 'is_shot-0',\n",
       "       'is_goal-0', 'event_id-0', 'goal_diff-0', 'seconds_remaining-0',\n",
       "       'diff_x-0', 'diff_y-0', 'distance_covered-0',\n",
       "       'start_distance_to_goal-0', 'end_distance_to_goal-0', 'zone_diff-0',\n",
       "       'poss_status-0', 'diff_angle_to_goal-0', 'non_shot_xg-0', 'game_id-1',\n",
       "       'team_id-1', 'player_id-1', 'period-1', 'x_coord-1', 'y_coord-1',\n",
       "       'x_coord_2-1', 'y_coord_2-1', 'is_home-1', 'is_shot-1', 'is_goal-1',\n",
       "       'event_id-1', 'goal_diff-1', 'seconds_remaining-1', 'diff_x-1',\n",
       "       'diff_y-1', 'distance_covered-1', 'start_distance_to_goal-1',\n",
       "       'end_distance_to_goal-1', 'zone_diff-1', 'poss_status-1',\n",
       "       'diff_angle_to_goal-1', 'non_shot_xg-1', 'game_id-2', 'team_id-2',\n",
       "       'player_id-2', 'period-2', 'x_coord-2', 'y_coord-2', 'x_coord_2-2',\n",
       "       'y_coord_2-2', 'is_home-2', 'is_shot-2', 'is_goal-2', 'event_id-2',\n",
       "       'goal_diff-2', 'seconds_remaining-2', 'diff_x-2', 'diff_y-2',\n",
       "       'distance_covered-2', 'start_distance_to_goal-2',\n",
       "       'end_distance_to_goal-2', 'zone_diff-2', 'poss_status-2',\n",
       "       'diff_angle_to_goal-2', 'non_shot_xg-2', 'team-0', 'team-1', 'team-2',\n",
       "       'xdiff_sequenc_pre', 'ydiff_sequenc_pre', 'time_sequence_pre'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 25
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 25;\n                var nbb_unformatted_code = \"df_features.columns\";\n                var nbb_formatted_code = \"df_features.columns\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "df_features.columns"
   ]
  },
  {
   "source": [
    "# Split Dataset & Train Classifiers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 26;\n                var nbb_unformatted_code = \"labels = ['scores','concedes']\\nfeat = ['start_distance_to_goal-0', 'end_distance_to_goal-0', 'start_distance_to_goal-1', 'end_distance_to_goal-1', 'start_distance_to_goal-2', 'end_distance_to_goal-2','team-1', 'team-2','seconds_remaining-0','goal_diff-0','zone_diff-0','zone_diff-1','zone_diff-2','poss_status-0','poss_status-1','poss_status-2', 'diff_angle_to_goal-0','diff_angle_to_goal-1','diff_angle_to_goal-2','non_shot_xg-0','non_shot_xg-1','non_shot_xg-2']\";\n                var nbb_formatted_code = \"labels = [\\\"scores\\\", \\\"concedes\\\"]\\nfeat = [\\n    \\\"start_distance_to_goal-0\\\",\\n    \\\"end_distance_to_goal-0\\\",\\n    \\\"start_distance_to_goal-1\\\",\\n    \\\"end_distance_to_goal-1\\\",\\n    \\\"start_distance_to_goal-2\\\",\\n    \\\"end_distance_to_goal-2\\\",\\n    \\\"team-1\\\",\\n    \\\"team-2\\\",\\n    \\\"seconds_remaining-0\\\",\\n    \\\"goal_diff-0\\\",\\n    \\\"zone_diff-0\\\",\\n    \\\"zone_diff-1\\\",\\n    \\\"zone_diff-2\\\",\\n    \\\"poss_status-0\\\",\\n    \\\"poss_status-1\\\",\\n    \\\"poss_status-2\\\",\\n    \\\"diff_angle_to_goal-0\\\",\\n    \\\"diff_angle_to_goal-1\\\",\\n    \\\"diff_angle_to_goal-2\\\",\\n    \\\"non_shot_xg-0\\\",\\n    \\\"non_shot_xg-1\\\",\\n    \\\"non_shot_xg-2\\\",\\n]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "labels = ['scores','concedes']\n",
    "feat = ['start_distance_to_goal-0', 'end_distance_to_goal-0', 'start_distance_to_goal-1', 'end_distance_to_goal-1', 'start_distance_to_goal-2', 'end_distance_to_goal-2','team-1', 'team-2','seconds_remaining-0','goal_diff-0','zone_diff-0','zone_diff-1','zone_diff-2','poss_status-0','poss_status-1','poss_status-2', 'diff_angle_to_goal-0','diff_angle_to_goal-1','diff_angle_to_goal-2','non_shot_xg-0','non_shot_xg-1','non_shot_xg-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s][13:46:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|     | 1/2 [00:00<00:00,  1.13it/s][13:46:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|| 2/2 [00:01<00:00,  1.14it/s]\n",
      "100%|| 2/2 [00:00<00:00, 71.18it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]0\n",
      "0\n",
      "[13:46:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|     | 1/2 [00:00<00:00,  1.14it/s][13:46:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|| 2/2 [00:01<00:00,  1.15it/s]\n",
      "100%|| 2/2 [00:00<00:00, 66.21it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]0\n",
      "0\n",
      "[13:46:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|     | 1/2 [00:00<00:00,  1.15it/s][13:46:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|| 2/2 [00:01<00:00,  1.15it/s]\n",
      "100%|| 2/2 [00:00<00:00, 69.08it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]0\n",
      "0\n",
      "[13:46:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|     | 1/2 [00:00<00:00,  1.10it/s][13:46:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|| 2/2 [00:01<00:00,  1.11it/s]\n",
      "100%|| 2/2 [00:00<00:00, 68.45it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]0\n",
      "0\n",
      "[13:46:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|     | 1/2 [00:00<00:00,  1.09it/s][13:46:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|| 2/2 [00:01<00:00,  1.11it/s]\n",
      "100%|| 2/2 [00:00<00:00, 57.06it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]0\n",
      "0\n",
      "[13:46:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|     | 1/2 [00:00<00:00,  1.10it/s][13:46:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|| 2/2 [00:01<00:00,  1.10it/s]\n",
      "100%|| 2/2 [00:00<00:00, 65.23it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]0\n",
      "0\n",
      "[13:46:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|     | 1/2 [00:00<00:00,  1.10it/s][13:46:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|| 2/2 [00:01<00:00,  1.11it/s]\n",
      "100%|| 2/2 [00:00<00:00, 65.87it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]0\n",
      "0\n",
      "[13:46:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|     | 1/2 [00:00<00:00,  1.20it/s][13:46:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|| 2/2 [00:01<00:00,  1.20it/s]\n",
      "100%|| 2/2 [00:00<00:00, 65.20it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]0\n",
      "0\n",
      "[13:46:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|     | 1/2 [00:00<00:00,  1.14it/s][13:46:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|| 2/2 [00:01<00:00,  1.15it/s]\n",
      "100%|| 2/2 [00:00<00:00, 71.66it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]0\n",
      "0\n",
      "[13:46:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|     | 1/2 [00:00<00:00,  1.11it/s][13:46:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|| 2/2 [00:01<00:00,  1.13it/s]\n",
      "100%|| 2/2 [00:00<00:00, 71.75it/s]0\n",
      "0\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 27;\n                var nbb_unformatted_code = \"df_model = pd.concat([df_features,df_labels],axis=1)\\ndf_score_concede_prob = pd.DataFrame()\\nkf = KFold(10, shuffle=True)\\n\\nfor train_idx, test_idx in kf.split(df_model):\\n    train_data = df_model.iloc[train_idx].copy()\\n    test_data = df_model.iloc[test_idx].copy()\\n\\n    models = {}\\n    for label in tqdm(labels):\\n        model = XGBClassifier(\\n            n_estimators=50,\\n            max_depth=3\\n        )\\n        model.fit(\\n            X=train_data[feat],\\n            y=train_data[label]\\n        )\\n        models[label] = model\\n\\n    dfs_predictions = {}\\n    for label in tqdm(labels):\\n        model = models[label]\\n        probabilities = model.predict_proba(test_data[feat])\\n        predictions = probabilities[:, 1]\\n        print(np.isnan(probabilities).sum())\\n        dfs_predictions[label] = pd.Series(predictions, index=test_data.index)\\n    df_predictions = pd.concat(dfs_predictions, axis=1)\\n    df_score_concede_prob = df_score_concede_prob.append(df_predictions)\";\n                var nbb_formatted_code = \"df_model = pd.concat([df_features, df_labels], axis=1)\\ndf_score_concede_prob = pd.DataFrame()\\nkf = KFold(10, shuffle=True)\\n\\nfor train_idx, test_idx in kf.split(df_model):\\n    train_data = df_model.iloc[train_idx].copy()\\n    test_data = df_model.iloc[test_idx].copy()\\n\\n    models = {}\\n    for label in tqdm(labels):\\n        model = XGBClassifier(n_estimators=50, max_depth=3)\\n        model.fit(X=train_data[feat], y=train_data[label])\\n        models[label] = model\\n\\n    dfs_predictions = {}\\n    for label in tqdm(labels):\\n        model = models[label]\\n        probabilities = model.predict_proba(test_data[feat])\\n        predictions = probabilities[:, 1]\\n        print(np.isnan(probabilities).sum())\\n        dfs_predictions[label] = pd.Series(predictions, index=test_data.index)\\n    df_predictions = pd.concat(dfs_predictions, axis=1)\\n    df_score_concede_prob = df_score_concede_prob.append(df_predictions)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "df_model = pd.concat([df_features,df_labels],axis=1)\n",
    "df_score_concede_prob = pd.DataFrame()\n",
    "kf = KFold(10, shuffle=True)\n",
    "\n",
    "for train_idx, test_idx in kf.split(df_model):\n",
    "    train_data = df_model.iloc[train_idx].copy()\n",
    "    test_data = df_model.iloc[test_idx].copy()\n",
    "\n",
    "    models = {}\n",
    "    for label in tqdm(labels):\n",
    "        model = XGBClassifier(\n",
    "            n_estimators=50,\n",
    "            max_depth=3\n",
    "        )\n",
    "        model.fit(\n",
    "            X=train_data[feat],\n",
    "            y=train_data[label]\n",
    "        )\n",
    "        models[label] = model\n",
    "\n",
    "    dfs_predictions = {}\n",
    "    for label in tqdm(labels):\n",
    "        model = models[label]\n",
    "        probabilities = model.predict_proba(test_data[feat])\n",
    "        predictions = probabilities[:, 1]\n",
    "        print(np.isnan(probabilities).sum())\n",
    "        dfs_predictions[label] = pd.Series(predictions, index=test_data.index)\n",
    "    df_predictions = pd.concat(dfs_predictions, axis=1)\n",
    "    df_score_concede_prob = df_score_concede_prob.append(df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 28;\n                var nbb_unformatted_code = \"dfs_actions = []\\ndfs_actions.append(womens)\\ndf_actions = pd.concat(dfs_actions).reset_index(drop=True)\\n\\ndf_actions_predictions = pd.concat([df_actions, df_score_concede_prob], axis=1)\\ndf_actions_predictions = df_actions_predictions.dropna(subset=['start_distance_to_goal', 'end_distance_to_goal', 'diff_x', 'diff_y',\\n       'distance_covered', 'scores', 'concedes'])\";\n                var nbb_formatted_code = \"dfs_actions = []\\ndfs_actions.append(womens)\\ndf_actions = pd.concat(dfs_actions).reset_index(drop=True)\\n\\ndf_actions_predictions = pd.concat([df_actions, df_score_concede_prob], axis=1)\\ndf_actions_predictions = df_actions_predictions.dropna(\\n    subset=[\\n        \\\"start_distance_to_goal\\\",\\n        \\\"end_distance_to_goal\\\",\\n        \\\"diff_x\\\",\\n        \\\"diff_y\\\",\\n        \\\"distance_covered\\\",\\n        \\\"scores\\\",\\n        \\\"concedes\\\",\\n    ]\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "dfs_actions = []\n",
    "dfs_actions.append(womens)\n",
    "df_actions = pd.concat(dfs_actions).reset_index(drop=True)\n",
    "\n",
    "df_actions_predictions = pd.concat([df_actions, df_score_concede_prob], axis=1)\n",
    "df_actions_predictions = df_actions_predictions.dropna(subset=['start_distance_to_goal', 'end_distance_to_goal', 'diff_x', 'diff_y',\n",
    "       'distance_covered', 'scores', 'concedes'])"
   ]
  },
  {
   "source": [
    "# calculate the VAEP value"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 29;\n                var nbb_unformatted_code = \"def prev(x: pd.Series) -> pd.Series:\\n    prev_x = x.shift(1)\\n    prev_x[:1] = x.values[0]\\n    return prev_x\";\n                var nbb_formatted_code = \"def prev(x: pd.Series) -> pd.Series:\\n    prev_x = x.shift(1)\\n    prev_x[:1] = x.values[0]\\n    return prev_x\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "def prev(x: pd.Series) -> pd.Series:\n",
    "    prev_x = x.shift(1)\n",
    "    prev_x[:1] = x.values[0]\n",
    "    return prev_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 30;\n                var nbb_unformatted_code = \"dfs_values = []\\ndf_values = pd.DataFrame()\\n\\nsameteam = prev(df_actions_predictions.team_id) == df_actions_predictions.team_id\\nprev_scores = prev(df_actions_predictions.scores) * sameteam + prev(df_actions_predictions.concedes) * (~sameteam)\\nprev_concedes = prev(df_actions_predictions.concedes) * sameteam + prev(df_actions_predictions.scores) * (~sameteam)\\n\\ntoolong_idx = abs(prev(df_actions_predictions.seconds_remaining) - df_actions_predictions.seconds_remaining) > 10\\nprev_scores[toolong_idx] = 0\\nprev_concedes[toolong_idx] = 0\\n\\nprevgoal_idx = prev(df_actions_predictions.event) == 'Goal'\\nprev_scores[prevgoal_idx] = 0\\nprev_concedes[prevgoal_idx] = 0\\n\\ndf_values['offensive_value'] = df_actions_predictions.scores - prev_scores\\ndf_values['defensive_value'] = df_actions_predictions.concedes - prev_concedes\\ndf_values['vaep'] = df_values['offensive_value'] + df_values['defensive_value']\";\n                var nbb_formatted_code = \"dfs_values = []\\ndf_values = pd.DataFrame()\\n\\nsameteam = prev(df_actions_predictions.team_id) == df_actions_predictions.team_id\\nprev_scores = prev(df_actions_predictions.scores) * sameteam + prev(\\n    df_actions_predictions.concedes\\n) * (~sameteam)\\nprev_concedes = prev(df_actions_predictions.concedes) * sameteam + prev(\\n    df_actions_predictions.scores\\n) * (~sameteam)\\n\\ntoolong_idx = (\\n    abs(\\n        prev(df_actions_predictions.seconds_remaining)\\n        - df_actions_predictions.seconds_remaining\\n    )\\n    > 10\\n)\\nprev_scores[toolong_idx] = 0\\nprev_concedes[toolong_idx] = 0\\n\\nprevgoal_idx = prev(df_actions_predictions.event) == \\\"Goal\\\"\\nprev_scores[prevgoal_idx] = 0\\nprev_concedes[prevgoal_idx] = 0\\n\\ndf_values[\\\"offensive_value\\\"] = df_actions_predictions.scores - prev_scores\\ndf_values[\\\"defensive_value\\\"] = df_actions_predictions.concedes - prev_concedes\\ndf_values[\\\"vaep\\\"] = df_values[\\\"offensive_value\\\"] + df_values[\\\"defensive_value\\\"]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "dfs_values = []\n",
    "df_values = pd.DataFrame()\n",
    "\n",
    "sameteam = prev(df_actions_predictions.team_id) == df_actions_predictions.team_id\n",
    "prev_scores = prev(df_actions_predictions.scores) * sameteam + prev(df_actions_predictions.concedes) * (~sameteam)\n",
    "prev_concedes = prev(df_actions_predictions.concedes) * sameteam + prev(df_actions_predictions.scores) * (~sameteam)\n",
    "\n",
    "toolong_idx = abs(prev(df_actions_predictions.seconds_remaining) - df_actions_predictions.seconds_remaining) > 10\n",
    "prev_scores[toolong_idx] = 0\n",
    "prev_concedes[toolong_idx] = 0\n",
    "\n",
    "prevgoal_idx = prev(df_actions_predictions.event) == 'Goal'\n",
    "prev_scores[prevgoal_idx] = 0\n",
    "prev_concedes[prevgoal_idx] = 0\n",
    "\n",
    "df_values['offensive_value'] = df_actions_predictions.scores - prev_scores\n",
    "df_values['defensive_value'] = df_actions_predictions.concedes - prev_concedes\n",
    "df_values['vaep'] = df_values['offensive_value'] + df_values['defensive_value']"
   ]
  },
  {
   "source": [
    "# Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 31;\n                var nbb_unformatted_code = \"df_final = pd.concat([df_actions_predictions,df_values],axis=1).dropna(subset=['vaep'])\\ndf_ranking = (df_final[['player','team','vaep']]\\n.groupby(['player','team'])\\n.agg(vaep_count=('vaep','count'),\\nvaep_mean=('vaep','mean'),\\nvaep_sum=('vaep','sum'))\\n.sort_values('vaep_sum',ascending=False)\\n.reset_index()\\n)\\n\\ndf_rank_events = (df_final[['event','vaep']]\\n.groupby(['event'])\\n.agg(vaep_count=('vaep','count'),\\nvaep_mean=('vaep','mean'),\\nvaep_sum=('vaep','sum'))\\n.sort_values('vaep_sum',ascending=False)\\n.reset_index()\\n)\\n\\ndf_zone_entries = (df_final.loc[womens['event']=='Zone Entry',['detail_1','defensive_value','offensive_value','vaep']]\\n.groupby(['detail_1'])\\n.agg(vaep_count=('vaep','count'),\\nvaep_mean=('vaep','mean'),\\nvaep_sum=('vaep','sum'))\\n.sort_values('vaep_sum',ascending=False)\\n.reset_index()\\n)\\n\\ndf_rank_strength = (df_final[['strength_state','event','vaep']]\\n.groupby(['strength_state','event'])\\n.agg(vaep_count=('vaep','count'),\\nvaep_mean=('vaep','mean'),\\nvaep_sum=('vaep','sum'))\\n.sort_values('vaep_sum',ascending=False)\\n.reset_index()\\n)\";\n                var nbb_formatted_code = \"df_final = pd.concat([df_actions_predictions, df_values], axis=1).dropna(\\n    subset=[\\\"vaep\\\"]\\n)\\ndf_ranking = (\\n    df_final[[\\\"player\\\", \\\"team\\\", \\\"vaep\\\"]]\\n    .groupby([\\\"player\\\", \\\"team\\\"])\\n    .agg(\\n        vaep_count=(\\\"vaep\\\", \\\"count\\\"),\\n        vaep_mean=(\\\"vaep\\\", \\\"mean\\\"),\\n        vaep_sum=(\\\"vaep\\\", \\\"sum\\\"),\\n    )\\n    .sort_values(\\\"vaep_sum\\\", ascending=False)\\n    .reset_index()\\n)\\n\\ndf_rank_events = (\\n    df_final[[\\\"event\\\", \\\"vaep\\\"]]\\n    .groupby([\\\"event\\\"])\\n    .agg(\\n        vaep_count=(\\\"vaep\\\", \\\"count\\\"),\\n        vaep_mean=(\\\"vaep\\\", \\\"mean\\\"),\\n        vaep_sum=(\\\"vaep\\\", \\\"sum\\\"),\\n    )\\n    .sort_values(\\\"vaep_sum\\\", ascending=False)\\n    .reset_index()\\n)\\n\\ndf_zone_entries = (\\n    df_final.loc[\\n        womens[\\\"event\\\"] == \\\"Zone Entry\\\",\\n        [\\\"detail_1\\\", \\\"defensive_value\\\", \\\"offensive_value\\\", \\\"vaep\\\"],\\n    ]\\n    .groupby([\\\"detail_1\\\"])\\n    .agg(\\n        vaep_count=(\\\"vaep\\\", \\\"count\\\"),\\n        vaep_mean=(\\\"vaep\\\", \\\"mean\\\"),\\n        vaep_sum=(\\\"vaep\\\", \\\"sum\\\"),\\n    )\\n    .sort_values(\\\"vaep_sum\\\", ascending=False)\\n    .reset_index()\\n)\\n\\ndf_rank_strength = (\\n    df_final[[\\\"strength_state\\\", \\\"event\\\", \\\"vaep\\\"]]\\n    .groupby([\\\"strength_state\\\", \\\"event\\\"])\\n    .agg(\\n        vaep_count=(\\\"vaep\\\", \\\"count\\\"),\\n        vaep_mean=(\\\"vaep\\\", \\\"mean\\\"),\\n        vaep_sum=(\\\"vaep\\\", \\\"sum\\\"),\\n    )\\n    .sort_values(\\\"vaep_sum\\\", ascending=False)\\n    .reset_index()\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "df_final = pd.concat([df_actions_predictions,df_values],axis=1).dropna(subset=['vaep'])\n",
    "df_ranking = (df_final[['player','team','vaep']]\n",
    ".groupby(['player','team'])\n",
    ".agg(vaep_count=('vaep','count'),\n",
    "vaep_mean=('vaep','mean'),\n",
    "vaep_sum=('vaep','sum'))\n",
    ".sort_values('vaep_sum',ascending=False)\n",
    ".reset_index()\n",
    ")\n",
    "\n",
    "df_rank_events = (df_final[['event','vaep']]\n",
    ".groupby(['event'])\n",
    ".agg(vaep_count=('vaep','count'),\n",
    "vaep_mean=('vaep','mean'),\n",
    "vaep_sum=('vaep','sum'))\n",
    ".sort_values('vaep_sum',ascending=False)\n",
    ".reset_index()\n",
    ")\n",
    "\n",
    "df_zone_entries = (df_final.loc[womens['event']=='Zone Entry',['detail_1','defensive_value','offensive_value','vaep']]\n",
    ".groupby(['detail_1'])\n",
    ".agg(vaep_count=('vaep','count'),\n",
    "vaep_mean=('vaep','mean'),\n",
    "vaep_sum=('vaep','sum'))\n",
    ".sort_values('vaep_sum',ascending=False)\n",
    ".reset_index()\n",
    ")\n",
    "\n",
    "df_rank_strength = (df_final[['strength_state','event','vaep']]\n",
    ".groupby(['strength_state','event'])\n",
    ".agg(vaep_count=('vaep','count'),\n",
    "vaep_mean=('vaep','mean'),\n",
    "vaep_sum=('vaep','sum'))\n",
    ".sort_values('vaep_sum',ascending=False)\n",
    ".reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['game_date', 'home_team', 'away_team', 'period', 'clock',\n",
       "       'home_team_skaters', 'away_team_skaters', 'home_team_goals',\n",
       "       'away_team_goals', 'team', 'player', 'event', 'x_coord', 'y_coord',\n",
       "       'detail_1', 'detail_2', 'detail_3', 'detail_4', 'player_2', 'x_coord_2',\n",
       "       'y_coord_2', 'game_id', 'is_home', 'is_shot', 'is_goal', 'event_id',\n",
       "       'team_id', 'player_id', 'detail_1_code', 'detail_2_code',\n",
       "       'detail_3_code', 'detail_4_code', 'goal_diff', 'seconds_remaining',\n",
       "       'poss_status', 'strength_state', 'zone_1', 'zone_2', 'zone_diff',\n",
       "       'start_distance_to_goal', 'end_distance_to_goal', 'diff_x', 'diff_y',\n",
       "       'distance_covered', 'angle_to_goal_start', 'angle_to_goal_end',\n",
       "       'diff_angle_to_goal', 'non_shot_xg', 'scores', 'concedes',\n",
       "       'offensive_value', 'defensive_value', 'vaep'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 32
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 32;\n                var nbb_unformatted_code = \"df_final.columns\";\n                var nbb_formatted_code = \"df_final.columns\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    player                             team  vaep_count  \\\n",
       "0          Natalie Spooner         Olympic (Women) - Canada         411   \n",
       "1         Rebecca Johnston         Olympic (Women) - Canada         686   \n",
       "2  Kendall Coyne Schofield  Olympic (Women) - United States         466   \n",
       "3        Christina Putigna                     Boston Pride         365   \n",
       "4            Hilary Knight  Olympic (Women) - United States         447   \n",
       "5           Meghan Lorence              Minnesota Whitecaps         229   \n",
       "6            Meghan Agosta         Olympic (Women) - Canada         324   \n",
       "7              Sarah Nurse         Olympic (Women) - Canada         395   \n",
       "8       Taylor Wenczkowski                     Boston Pride         304   \n",
       "9        Autumn MacDougall                   Buffalo Beauts         285   \n",
       "\n",
       "   vaep_mean  vaep_sum  \n",
       "0   0.011220  4.611493  \n",
       "1   0.005697  3.908050  \n",
       "2   0.007629  3.554918  \n",
       "3   0.008796  3.210490  \n",
       "4   0.006685  2.988146  \n",
       "5   0.012790  2.928910  \n",
       "6   0.007937  2.571652  \n",
       "7   0.006459  2.551470  \n",
       "8   0.008384  2.548830  \n",
       "9   0.008468  2.413460  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>player</th>\n      <th>team</th>\n      <th>vaep_count</th>\n      <th>vaep_mean</th>\n      <th>vaep_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Natalie Spooner</td>\n      <td>Olympic (Women) - Canada</td>\n      <td>411</td>\n      <td>0.011220</td>\n      <td>4.611493</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Rebecca Johnston</td>\n      <td>Olympic (Women) - Canada</td>\n      <td>686</td>\n      <td>0.005697</td>\n      <td>3.908050</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kendall Coyne Schofield</td>\n      <td>Olympic (Women) - United States</td>\n      <td>466</td>\n      <td>0.007629</td>\n      <td>3.554918</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Christina Putigna</td>\n      <td>Boston Pride</td>\n      <td>365</td>\n      <td>0.008796</td>\n      <td>3.210490</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hilary Knight</td>\n      <td>Olympic (Women) - United States</td>\n      <td>447</td>\n      <td>0.006685</td>\n      <td>2.988146</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Meghan Lorence</td>\n      <td>Minnesota Whitecaps</td>\n      <td>229</td>\n      <td>0.012790</td>\n      <td>2.928910</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Meghan Agosta</td>\n      <td>Olympic (Women) - Canada</td>\n      <td>324</td>\n      <td>0.007937</td>\n      <td>2.571652</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Sarah Nurse</td>\n      <td>Olympic (Women) - Canada</td>\n      <td>395</td>\n      <td>0.006459</td>\n      <td>2.551470</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Taylor Wenczkowski</td>\n      <td>Boston Pride</td>\n      <td>304</td>\n      <td>0.008384</td>\n      <td>2.548830</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Autumn MacDougall</td>\n      <td>Buffalo Beauts</td>\n      <td>285</td>\n      <td>0.008468</td>\n      <td>2.413460</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 33;\n                var nbb_unformatted_code = \"df_ranking.head(10)\";\n                var nbb_formatted_code = \"df_ranking.head(10)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "df_ranking.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             event  vaep_count  vaep_mean    vaep_sum\n",
       "0             Shot        3524   0.043461  153.155273\n",
       "1             Play       14673   0.003820   56.047165\n",
       "2             Goal         132   0.384100   50.701187\n",
       "3       Zone Entry        3744   0.005183   19.405521\n",
       "4         Takeaway        2092   0.000632    1.323032\n",
       "5      Dump In/Out        3545   0.000172    0.608482\n",
       "6    Penalty Taken         260   0.001298    0.337507\n",
       "7  Incomplete Play        6111  -0.007413  -45.301025\n",
       "8      Faceoff Win        1629  -0.032298  -52.613205\n",
       "9    Puck Recovery       15174  -0.007565 -114.796928"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event</th>\n      <th>vaep_count</th>\n      <th>vaep_mean</th>\n      <th>vaep_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Shot</td>\n      <td>3524</td>\n      <td>0.043461</td>\n      <td>153.155273</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Play</td>\n      <td>14673</td>\n      <td>0.003820</td>\n      <td>56.047165</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Goal</td>\n      <td>132</td>\n      <td>0.384100</td>\n      <td>50.701187</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Zone Entry</td>\n      <td>3744</td>\n      <td>0.005183</td>\n      <td>19.405521</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Takeaway</td>\n      <td>2092</td>\n      <td>0.000632</td>\n      <td>1.323032</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Dump In/Out</td>\n      <td>3545</td>\n      <td>0.000172</td>\n      <td>0.608482</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Penalty Taken</td>\n      <td>260</td>\n      <td>0.001298</td>\n      <td>0.337507</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Incomplete Play</td>\n      <td>6111</td>\n      <td>-0.007413</td>\n      <td>-45.301025</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Faceoff Win</td>\n      <td>1629</td>\n      <td>-0.032298</td>\n      <td>-52.613205</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Puck Recovery</td>\n      <td>15174</td>\n      <td>-0.007565</td>\n      <td>-114.796928</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 34;\n                var nbb_unformatted_code = \"df_rank_events\";\n                var nbb_formatted_code = \"df_rank_events\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "df_rank_events"
   ]
  },
  {
   "source": [
    "# First Impression\n",
    "## What looks wrong here:\n",
    "* Takeaway gains possesion and has negative value\n",
    "* Incomplete Play loses Possession and has positive value\n",
    "* Faceoff Win: alth negative value\n",
    "* Puck Recovery\n",
    "\n",
    "## What looks right:\n",
    "* Shot: high value overall and mean\n",
    "* Goal: highest value mean\n",
    "* Play\n",
    "* zone entry: kinda right.\n",
    "* Dump in/out: low value. seems right\n",
    "* penalty taken: negative value\n",
    "\n",
    "# New Impression\n",
    "## What looks right now: \n",
    "* Takeaway has positive mean value now\n",
    "* Incomplete Play has now negative mean value \n",
    "* Puck Recovery can be for and against. There are positive and negative values \n",
    "## What is still wrong: \n",
    "* Faceoff Win still has \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  detail_1  vaep_count  vaep_mean   vaep_sum\n",
       "0  Carried        2316   0.007657  17.733377\n",
       "1   Played         261   0.003639   0.949745\n",
       "2   Dumped        1167   0.000619   0.722398"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>detail_1</th>\n      <th>vaep_count</th>\n      <th>vaep_mean</th>\n      <th>vaep_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Carried</td>\n      <td>2316</td>\n      <td>0.007657</td>\n      <td>17.733377</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Played</td>\n      <td>261</td>\n      <td>0.003639</td>\n      <td>0.949745</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dumped</td>\n      <td>1167</td>\n      <td>0.000619</td>\n      <td>0.722398</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 35;\n                var nbb_unformatted_code = \"df_zone_entries\";\n                var nbb_formatted_code = \"df_zone_entries\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "df_zone_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Carried    2316\n",
       "Dumped     1167\n",
       "Played      261\n",
       "Name: detail_1, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 36
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 36;\n                var nbb_unformatted_code = \"womens.loc[(womens['event']=='Zone Entry'),'detail_1'].value_counts(dropna=False)\";\n                var nbb_formatted_code = \"womens.loc[(womens[\\\"event\\\"] == \\\"Zone Entry\\\"), \\\"detail_1\\\"].value_counts(dropna=False)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "womens.loc[(womens['event']=='Zone Entry'),'detail_1'].value_counts(dropna=False)"
   ]
  }
 ]
}